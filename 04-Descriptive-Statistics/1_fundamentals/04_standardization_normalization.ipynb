{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization and Normalization\n",
    "\n",
    "**Essential Data Scaling Techniques for PCA and Machine Learning**\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the previous notebooks, we learned about variance, covariance, and correlation. But we encountered an important question: **How do we compare variables measured in different units?**\n",
    "\n",
    "Consider this agricultural scenario:\n",
    "- **Soil pH**: Range 5.0 to 8.0 (unitless, small scale)\n",
    "- **Nitrogen content**: Range 10 to 200 ppm (large scale)\n",
    "- **Organic matter**: Range 1% to 6% (percentage)\n",
    "\n",
    "If we analyze these together without scaling, variables with larger ranges will **dominate** the analysis. This is especially problematic for **Principal Component Analysis (PCA)**, where variance matters!\n",
    "\n",
    "### Why This Matters for PCA â­â­\n",
    "\n",
    "**PCA finds directions of maximum variance.** If one variable has a much larger variance simply because of its units (not because it's more important), PCA will focus on that variable and miss important patterns in other variables.\n",
    "\n",
    "**The solution**: Standardization and Normalization make variables comparable by putting them on the same scale.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. âœ“ Understand **why** scaling is necessary for PCA\n",
    "2. âœ“ Master **z-score standardization** (most common for PCA)\n",
    "3. âœ“ Learn **min-max normalization** and when to use it\n",
    "4. âœ“ Understand **robust scaling** for data with outliers\n",
    "5. âœ“ Visualize the **effect of scaling** on data\n",
    "6. âœ“ Know **when to standardize** before PCA\n",
    "7. âœ“ See how scaling affects **covariance vs correlation** matrices\n",
    "\n",
    "**Agricultural Context**: We'll use multi-variable soil data (pH, nitrogen, phosphorus, moisture) to demonstrate why scaling matters for analyzing soil properties together.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Scaling Problem\n",
    "\n",
    "Let's start by seeing the problem firsthand with real agricultural data.\n",
    "\n",
    "### Agricultural Scenario\n",
    "\n",
    "You have soil samples from 50 agricultural fields with the following measurements:\n",
    "- **pH**: 5.5 to 7.5 (small range, unitless)\n",
    "- **Nitrogen (N)**: 20 to 180 ppm (large range)\n",
    "- **Phosphorus (P)**: 10 to 90 ppm (medium range)\n",
    "- **Soil Moisture**: 15% to 35% (medium range)\n",
    "\n",
    "You want to understand the overall soil quality patterns. Should you analyze these variables directly, or scale them first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic agricultural soil data\n",
    "n_samples = 50\n",
    "\n",
    "# Different variables with different scales\n",
    "soil_pH = np.random.normal(6.5, 0.5, n_samples)  # Small range: ~5.5 to 7.5\n",
    "nitrogen_ppm = np.random.normal(100, 40, n_samples)  # Large range: ~20 to 180\n",
    "phosphorus_ppm = np.random.normal(50, 20, n_samples)  # Medium range: ~10 to 90\n",
    "moisture_pct = np.random.normal(25, 5, n_samples)  # Medium range: ~15 to 35\n",
    "\n",
    "# Create DataFrame\n",
    "soil_data = pd.DataFrame({\n",
    "    'pH': soil_pH,\n",
    "    'Nitrogen_ppm': nitrogen_ppm,\n",
    "    'Phosphorus_ppm': phosphorus_ppm,\n",
    "    'Moisture_%': moisture_pct\n",
    "})\n",
    "\n",
    "print(\"ğŸŒ¾ Soil Property Data Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(soil_data.describe().round(2))\n",
    "print(\"\\nğŸ“Š Notice the very different scales!\")\n",
    "print(f\"  â€¢ pH range: {soil_data['pH'].min():.2f} to {soil_data['pH'].max():.2f}\")\n",
    "print(f\"  â€¢ Nitrogen range: {soil_data['Nitrogen_ppm'].min():.2f} to {soil_data['Nitrogen_ppm'].max():.2f}\")\n",
    "print(f\"  â€¢ Phosphorus range: {soil_data['Phosphorus_ppm'].min():.2f} to {soil_data['Phosphorus_ppm'].max():.2f}\")\n",
    "print(f\"  â€¢ Moisture range: {soil_data['Moisture_%'].min():.2f} to {soil_data['Moisture_%'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the scaling problem\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('ğŸŒ¾ Soil Properties: Different Scales Create Comparison Problems', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "variables = ['pH', 'Nitrogen_ppm', 'Phosphorus_ppm', 'Moisture_%']\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "for idx, (var, color, ax) in enumerate(zip(variables, colors, axes.flat)):\n",
    "    ax.hist(soil_data[var], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(soil_data[var].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    ax.set_xlabel(var, fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=11)\n",
    "    ax.set_title(f'{var}\\nRange: {soil_data[var].min():.1f} to {soil_data[var].max():.1f}', \n",
    "                 fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâš ï¸  THE PROBLEM: Variables have vastly different ranges!\")\n",
    "print(\"   â†’ Nitrogen varies from 20-180 (range ~160)\")\n",
    "print(\"   â†’ pH varies from 5.5-7.5 (range ~2)\")\n",
    "print(\"   â†’ Without scaling, nitrogen will DOMINATE any analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Variance Problem for PCA\n",
    "\n",
    "Let's calculate the variance of each variable to see the problem clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate variance for each variable\n",
    "variances = soil_data.var()\n",
    "\n",
    "print(\"ğŸ“Š Variance of Each Soil Property (Unscaled)\")\n",
    "print(\"=\" * 60)\n",
    "for var, variance in variances.items():\n",
    "    print(f\"  {var:20s}: {variance:10.2f}\")\n",
    "\n",
    "print(\"\\nâš¡ KEY INSIGHT FOR PCA:\")\n",
    "print(f\"  Nitrogen variance is {variances['Nitrogen_ppm'] / variances['pH']:.0f}x larger than pH variance!\")\n",
    "print(\"  â†’ PCA will focus almost entirely on Nitrogen\")\n",
    "print(\"  â†’ pH patterns will be ignored, even if they're important!\")\n",
    "print(\"\\nğŸ’¡ SOLUTION: Standardize the data so all variables contribute equally!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize variance comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars = ax.bar(variances.index, variances.values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax.set_ylabel('Variance', fontsize=13, fontweight='bold')\n",
    "ax.set_title('ğŸš¨ The Scaling Problem: Variance Dominance\\n(Nitrogen has 640x more variance than pH!)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, var in zip(bars, variances.values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{var:.1f}',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=15, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ Without standardization, PCA would be dominated by Nitrogen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Z-Score Standardization â­â­\n",
    "\n",
    "**The most common scaling method for PCA!**\n",
    "\n",
    "### Definition\n",
    "\n",
    "Z-score standardization transforms each value by:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where:\n",
    "- $x$ = original value\n",
    "- $\\mu$ = mean of the variable\n",
    "- $\\sigma$ = standard deviation of the variable\n",
    "- $z$ = standardized value (z-score)\n",
    "\n",
    "### Properties After Standardization\n",
    "\n",
    "- **Mean = 0**: Data is centered at zero\n",
    "- **Standard Deviation = 1**: All variables have the same spread\n",
    "- **Shape Preserved**: The distribution shape doesn't change\n",
    "- **Units Removed**: Z-scores are unitless\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "A z-score tells you **how many standard deviations** a value is from the mean:\n",
    "- $z = 0$: At the mean\n",
    "- $z = 1$: One standard deviation above the mean\n",
    "- $z = -2$: Two standard deviations below the mean\n",
    "\n",
    "### Agricultural Example\n",
    "\n",
    "Let's standardize the soil pH data step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual z-score standardization for pH\n",
    "pH_values = soil_data['pH'].values\n",
    "\n",
    "# Step 1: Calculate mean\n",
    "pH_mean = np.mean(pH_values)\n",
    "print(\"Step 1: Calculate Mean\")\n",
    "print(f\"  Î¼ = {pH_mean:.3f}\")\n",
    "\n",
    "# Step 2: Calculate standard deviation\n",
    "pH_std = np.std(pH_values, ddof=1)  # Sample SD\n",
    "print(\"\\nStep 2: Calculate Standard Deviation\")\n",
    "print(f\"  Ïƒ = {pH_std:.3f}\")\n",
    "\n",
    "# Step 3: Subtract mean from each value\n",
    "pH_centered = pH_values - pH_mean\n",
    "print(\"\\nStep 3: Center the Data (x - Î¼)\")\n",
    "print(f\"  First 5 centered values: {pH_centered[:5].round(3)}\")\n",
    "\n",
    "# Step 4: Divide by standard deviation\n",
    "pH_standardized_manual = pH_centered / pH_std\n",
    "print(\"\\nStep 4: Scale by SD â†’ z = (x - Î¼) / Ïƒ\")\n",
    "print(f\"  First 5 z-scores: {pH_standardized_manual[:5].round(3)}\")\n",
    "\n",
    "# Verify properties\n",
    "print(\"\\nâœ“ Verification:\")\n",
    "print(f\"  Mean of z-scores: {np.mean(pH_standardized_manual):.10f}  (should be â‰ˆ 0)\")\n",
    "print(f\"  SD of z-scores: {np.std(pH_standardized_manual, ddof=1):.10f}  (should be â‰ˆ 1)\")\n",
    "\n",
    "# Compare with NumPy's implementation\n",
    "pH_standardized_numpy = (pH_values - pH_mean) / pH_std\n",
    "print(\"\\nâœ“ NumPy matches our manual calculation:\", \n",
    "      np.allclose(pH_standardized_manual, pH_standardized_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize All Soil Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all variables\n",
    "soil_standardized = pd.DataFrame()\n",
    "\n",
    "for column in soil_data.columns:\n",
    "    values = soil_data[column].values\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values, ddof=1)\n",
    "    \n",
    "    # Z-score standardization\n",
    "    z_scores = (values - mean_val) / std_val\n",
    "    \n",
    "    soil_standardized[column + '_z'] = z_scores\n",
    "\n",
    "print(\"ğŸŒ¾ Standardized Soil Data Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(soil_standardized.describe().round(3))\n",
    "\n",
    "print(\"\\nâœ“ Notice:\")\n",
    "print(\"  â€¢ All means are now â‰ˆ 0\")\n",
    "print(\"  â€¢ All standard deviations are now â‰ˆ 1\")\n",
    "print(\"  â€¢ All variables are now on the SAME SCALE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize before and after standardization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('ğŸ”„ Before and After Standardization\\n(Same Distribution Shape, Different Scale)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# Original data\n",
    "for idx, (var, color) in enumerate(zip(soil_data.columns, colors)):\n",
    "    ax = axes[0, idx]\n",
    "    ax.hist(soil_data[var], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(soil_data[var].mean(), color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_title(f'Original: {var}', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add mean and SD text\n",
    "    ax.text(0.05, 0.95, f'Î¼ = {soil_data[var].mean():.1f}\\nÏƒ = {soil_data[var].std():.1f}',\n",
    "            transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Standardized data\n",
    "for idx, (var, color) in enumerate(zip(soil_standardized.columns, colors)):\n",
    "    ax = axes[1, idx]\n",
    "    ax.hist(soil_standardized[var], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(soil_standardized[var].mean(), color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_title(f'Standardized: {var}', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Z-score', fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add mean and SD text\n",
    "    ax.text(0.05, 0.95, f'Î¼ = {soil_standardized[var].mean():.3f}\\nÏƒ = {soil_standardized[var].std():.3f}',\n",
    "            transform=ax.transAxes, fontsize=9, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ KEY OBSERVATION:\")\n",
    "print(\"  â€¢ Distribution SHAPE is preserved\")\n",
    "print(\"  â€¢ But now all variables are on the SAME SCALE (-3 to +3)\")\n",
    "print(\"  â€¢ Perfect for PCA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance After Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare variances before and after\n",
    "variances_standardized = soil_standardized.var()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('âš–ï¸ Variance Comparison: Before and After Standardization', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Before\n",
    "ax1.bar(variances.index, variances.values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('Variance', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('BEFORE Standardization\\n(Nitrogen dominates!)', fontsize=12)\n",
    "ax1.grid(True, axis='y', alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=15)\n",
    "\n",
    "for i, (var, v) in enumerate(zip(variances.index, variances.values)):\n",
    "    ax1.text(i, v, f'{v:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# After\n",
    "ax2.bar(range(len(variances_standardized)), variances_standardized.values, \n",
    "        color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax2.set_ylabel('Variance', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('AFTER Standardization\\n(All equal to 1!)', fontsize=12)\n",
    "ax2.set_xticks(range(len(variances_standardized)))\n",
    "ax2.set_xticklabels(soil_data.columns, rotation=15, ha='right')\n",
    "ax2.grid(True, axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0, 1.2])\n",
    "\n",
    "for i, v in enumerate(variances_standardized.values):\n",
    "    ax2.text(i, v, f'{v:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ CRITICAL FOR PCA:\")\n",
    "print(\"  â€¢ Before: Variances ranged from 0.25 to 1603\")\n",
    "print(\"  â€¢ After: All variances are exactly 1.0\")\n",
    "print(\"  â€¢ Now PCA will treat all variables EQUALLY!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Min-Max Normalization\n",
    "\n",
    "Another common scaling technique that scales data to a specific range (usually 0 to 1).\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$x_{\\text{normalized}} = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}$$\n",
    "\n",
    "### Properties\n",
    "\n",
    "- **Range**: Always between 0 and 1\n",
    "- **Preserves**: Original distribution shape\n",
    "- **Use When**: You need a specific range (e.g., for neural networks)\n",
    "- **Sensitive to**: Outliers (they compress the range)\n",
    "\n",
    "### When to Use Normalization vs Standardization\n",
    "\n",
    "- **Standardization (Z-score)**: Use for PCA, when you don't know the distribution, or when you have outliers that shouldn't dominate\n",
    "- **Normalization (Min-Max)**: Use when you need a bounded range, for neural networks, or when all values must be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-max normalization for pH\n",
    "pH_values = soil_data['pH'].values\n",
    "\n",
    "# Step 1: Find min and max\n",
    "pH_min = np.min(pH_values)\n",
    "pH_max = np.max(pH_values)\n",
    "print(\"Step 1: Find Min and Max\")\n",
    "print(f\"  Min = {pH_min:.3f}\")\n",
    "print(f\"  Max = {pH_max:.3f}\")\n",
    "print(f\"  Range = {pH_max - pH_min:.3f}\")\n",
    "\n",
    "# Step 2: Apply formula\n",
    "pH_normalized = (pH_values - pH_min) / (pH_max - pH_min)\n",
    "print(\"\\nStep 2: Apply Formula â†’ (x - min) / (max - min)\")\n",
    "print(f\"  First 5 normalized values: {pH_normalized[:5].round(3)}\")\n",
    "\n",
    "# Verify properties\n",
    "print(\"\\nâœ“ Verification:\")\n",
    "print(f\"  Min of normalized data: {np.min(pH_normalized):.10f}  (should be 0)\")\n",
    "print(f\"  Max of normalized data: {np.max(pH_normalized):.10f}  (should be 1)\")\n",
    "print(f\"  Mean of normalized data: {np.mean(pH_normalized):.3f}  (not necessarily 0.5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all variables\n",
    "soil_normalized = pd.DataFrame()\n",
    "\n",
    "for column in soil_data.columns:\n",
    "    values = soil_data[column].values\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    \n",
    "    # Min-max normalization\n",
    "    normalized = (values - min_val) / (max_val - min_val)\n",
    "    \n",
    "    soil_normalized[column + '_norm'] = normalized\n",
    "\n",
    "print(\"ğŸŒ¾ Normalized Soil Data Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(soil_normalized.describe().round(3))\n",
    "\n",
    "print(\"\\nâœ“ Notice:\")\n",
    "print(\"  â€¢ All minimums are now 0.0\")\n",
    "print(\"  â€¢ All maximums are now 1.0\")\n",
    "print(\"  â€¢ Means are NOT necessarily 0.5 (depends on distribution)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare standardization vs normalization\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 10))\n",
    "fig.suptitle('ğŸ“Š Comparison: Original vs Standardized vs Normalized', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "for idx, (var, color) in enumerate(zip(soil_data.columns, colors)):\n",
    "    # Original\n",
    "    axes[0, idx].hist(soil_data[var], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    axes[0, idx].set_title(f'Original: {var}', fontsize=10, fontweight='bold')\n",
    "    axes[0, idx].set_ylabel('Frequency', fontsize=9)\n",
    "    axes[0, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Standardized\n",
    "    axes[1, idx].hist(soil_standardized[var + '_z'], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    axes[1, idx].set_title(f'Standardized (Z-score)', fontsize=10, fontweight='bold')\n",
    "    axes[1, idx].set_ylabel('Frequency', fontsize=9)\n",
    "    axes[1, idx].set_xlabel('Z-score', fontsize=9)\n",
    "    axes[1, idx].grid(True, alpha=0.3)\n",
    "    axes[1, idx].axvline(0, color='red', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Normalized\n",
    "    axes[2, idx].hist(soil_normalized[var + '_norm'], bins=15, color=color, alpha=0.7, edgecolor='black')\n",
    "    axes[2, idx].set_title(f'Normalized (0-1)', fontsize=10, fontweight='bold')\n",
    "    axes[2, idx].set_ylabel('Frequency', fontsize=9)\n",
    "    axes[2, idx].set_xlabel('Normalized Value', fontsize=9)\n",
    "    axes[2, idx].grid(True, alpha=0.3)\n",
    "    axes[2, idx].set_xlim([-0.1, 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ” Key Differences:\")\n",
    "print(\"  Standardization (Z-score):\")\n",
    "print(\"    âœ“ Mean = 0, SD = 1\")\n",
    "print(\"    âœ“ Range: typically -3 to +3 (can be beyond)\")\n",
    "print(\"    âœ“ Best for PCA\")\n",
    "print(\"\\n  Normalization (Min-Max):\")\n",
    "print(\"    âœ“ Range = exactly 0 to 1\")\n",
    "print(\"    âœ“ Mean = varies by distribution\")\n",
    "print(\"    âœ“ Best for neural networks, bounded ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Robust Scaling\n",
    "\n",
    "When data has **outliers**, robust scaling uses the **median** and **interquartile range (IQR)** instead of mean and standard deviation.\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$x_{\\text{robust}} = \\frac{x - \\text{median}}{\\text{IQR}}$$\n",
    "\n",
    "Where IQR = Q3 - Q1\n",
    "\n",
    "### Properties\n",
    "\n",
    "- **Robust to outliers**: Median and IQR are not affected by extreme values\n",
    "- **Median = 0** after scaling\n",
    "- **Range**: Not bounded to [0, 1] or [-3, 3]\n",
    "- **Use When**: Your data has significant outliers that you want to keep\n",
    "\n",
    "### Agricultural Example with Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data with outliers\n",
    "yield_data = np.random.normal(5000, 800, 48)  # Normal yields\n",
    "outliers = np.array([1500, 9500])  # Two outlier fields\n",
    "yield_with_outliers = np.concatenate([yield_data, outliers])\n",
    "\n",
    "print(\"ğŸŒ¾ Wheat Yield Data (kg/hectare)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean: {np.mean(yield_with_outliers):.1f}\")\n",
    "print(f\"Median: {np.median(yield_with_outliers):.1f}\")\n",
    "print(f\"Standard Deviation: {np.std(yield_with_outliers, ddof=1):.1f}\")\n",
    "print(f\"IQR: {np.percentile(yield_with_outliers, 75) - np.percentile(yield_with_outliers, 25):.1f}\")\n",
    "print(f\"\\nMin: {np.min(yield_with_outliers):.1f} (OUTLIER!)\")\n",
    "print(f\"Max: {np.max(yield_with_outliers):.1f} (OUTLIER!)\")\n",
    "\n",
    "# Standard scaling\n",
    "mean_yield = np.mean(yield_with_outliers)\n",
    "std_yield = np.std(yield_with_outliers, ddof=1)\n",
    "yield_standardized = (yield_with_outliers - mean_yield) / std_yield\n",
    "\n",
    "# Robust scaling\n",
    "median_yield = np.median(yield_with_outliers)\n",
    "q1 = np.percentile(yield_with_outliers, 25)\n",
    "q3 = np.percentile(yield_with_outliers, 75)\n",
    "iqr_yield = q3 - q1\n",
    "yield_robust = (yield_with_outliers - median_yield) / iqr_yield\n",
    "\n",
    "print(\"\\nğŸ“Š Scaling Comparison:\")\n",
    "print(f\"Standard scaling range: {yield_standardized.min():.2f} to {yield_standardized.max():.2f}\")\n",
    "print(f\"Robust scaling range: {yield_robust.min():.2f} to {yield_robust.max():.2f}\")\n",
    "print(\"\\nğŸ’¡ Robust scaling compresses outliers less!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the difference\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle('ğŸ¯ Robust Scaling vs Standard Scaling (With Outliers)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Original data\n",
    "axes[0].hist(yield_with_outliers, bins=20, color='#FF6B6B', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(mean_yield, color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "axes[0].axvline(median_yield, color='blue', linestyle='--', linewidth=2, label='Median')\n",
    "axes[0].set_xlabel('Yield (kg/ha)', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Original Data\\n(with outliers)', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Standard scaling\n",
    "axes[1].hist(yield_standardized, bins=20, color='#4ECDC4', alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Z-score', fontsize=11)\n",
    "axes[1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1].set_title('Standard Scaling\\n(outliers affect all values)', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Robust scaling\n",
    "axes[2].hist(yield_robust, bins=20, color='#45B7D1', alpha=0.7, edgecolor='black')\n",
    "axes[2].axvline(0, color='blue', linestyle='--', linewidth=2)\n",
    "axes[2].set_xlabel('Robust Score', fontsize=11)\n",
    "axes[2].set_ylabel('Frequency', fontsize=11)\n",
    "axes[2].set_title('Robust Scaling\\n(outliers isolated)', fontsize=12, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ When to Use Robust Scaling:\")\n",
    "print(\"  âœ“ Data has significant outliers\")\n",
    "print(\"  âœ“ Outliers are real (not errors) and should be kept\")\n",
    "print(\"  âœ“ You want outliers to have less influence on scaling\")\n",
    "print(\"\\nâš ï¸  For PCA: Usually use standard z-score scaling\")\n",
    "print(\"   But if outliers are problematic, robust scaling can help!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Impact on Covariance vs Correlation â­\n",
    "\n",
    "**This is CRITICAL for understanding PCA!**\n",
    "\n",
    "Remember from the previous notebook:\n",
    "- **Covariance Matrix**: Uses unscaled data\n",
    "- **Correlation Matrix**: Uses standardized data\n",
    "\n",
    "PCA can use either matrix, but:\n",
    "- **Covariance-based PCA**: Variables with larger variance dominate\n",
    "- **Correlation-based PCA**: All variables contribute equally (equivalent to standardizing first)\n",
    "\n",
    "### Let's See the Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute covariance matrix (unscaled data)\n",
    "cov_matrix = soil_data.cov()\n",
    "\n",
    "# Compute correlation matrix (equivalent to standardized covariance)\n",
    "corr_matrix = soil_data.corr()\n",
    "\n",
    "# Also compute covariance of standardized data\n",
    "cov_matrix_standardized = soil_standardized.cov()\n",
    "\n",
    "print(\"ğŸ“Š Covariance Matrix (Unscaled Data)\")\n",
    "print(\"=\" * 60)\n",
    "print(cov_matrix.round(2))\n",
    "print(\"\\nâš ï¸  Notice: Diagonal values (variances) are VERY different!\")\n",
    "print(f\"   pH variance: {cov_matrix.iloc[0,0]:.2f}\")\n",
    "print(f\"   Nitrogen variance: {cov_matrix.iloc[1,1]:.2f}\")\n",
    "print(f\"   â†’ Nitrogen is {cov_matrix.iloc[1,1] / cov_matrix.iloc[0,0]:.0f}x more variable\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š Correlation Matrix (Standardized Covariance)\")\n",
    "print(\"=\" * 60)\n",
    "print(corr_matrix.round(3))\n",
    "print(\"\\nâœ“ Notice: Diagonal values are all 1.0 (all variables equal)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š Covariance Matrix of Standardized Data\")\n",
    "print(\"=\" * 60)\n",
    "print(cov_matrix_standardized.round(3))\n",
    "print(\"\\nâœ“ This equals the correlation matrix!\")\n",
    "print(\"   Covariance of standardized data = Correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the matrices side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('ğŸ” Covariance vs Correlation Matrix for PCA', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Covariance matrix heatmap\n",
    "sns.heatmap(cov_matrix, annot=True, fmt='.1f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Covariance'}, ax=axes[0],\n",
    "            linewidths=1, linecolor='black')\n",
    "axes[0].set_title('Covariance Matrix\\n(Unscaled - Nitrogen Dominates)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "# Correlation matrix heatmap\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdYlBu_r', \n",
    "            cbar_kws={'label': 'Correlation'}, ax=axes[1],\n",
    "            linewidths=1, linecolor='black', vmin=-1, vmax=1)\n",
    "axes[1].set_title('Correlation Matrix\\n(Standardized - All Equal)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ¯ FOR PCA:\")\n",
    "print(\"  Left (Covariance): PCA will focus mainly on Nitrogen\")\n",
    "print(\"  Right (Correlation): PCA will consider all variables equally\")\n",
    "print(\"\\nğŸ’¡ RULE OF THUMB:\")\n",
    "print(\"  â€¢ Different units or scales â†’ STANDARDIZE â†’ Use correlation\")\n",
    "print(\"  â€¢ Same units and scale â†’ Can use covariance\")\n",
    "print(\"  â€¢ When in doubt â†’ STANDARDIZE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. When to Standardize for PCA â­â­\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**ALWAYS Standardize When:**\n",
    "1. âœ“ Variables have **different units** (pH, ppm, %, kg, etc.)\n",
    "2. âœ“ Variables have **different scales** (0-10 vs 0-1000)\n",
    "3. âœ“ You want **all variables to contribute equally**\n",
    "4. âœ“ You're **unsure** (standardizing is safer!)\n",
    "\n",
    "**Can Skip Standardization When:**\n",
    "1. âœ“ All variables have the **same units**\n",
    "2. âœ“ Variables are on **similar scales**\n",
    "3. âœ“ Larger variance variables are **truly more important**\n",
    "4. âœ“ You **specifically want** variables with more variance to dominate\n",
    "\n",
    "### Agricultural Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸŒ¾ Agricultural PCA Scenarios\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "scenarios = [\n",
    "    {\n",
    "        'name': 'Soil Chemistry Analysis',\n",
    "        'variables': ['pH (5-8)', 'N (ppm)', 'P (ppm)', 'K (ppm)', 'Moisture (%)'],\n",
    "        'standardize': 'YES âœ“',\n",
    "        'reason': 'Different units and scales - must standardize!'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Multi-Nutrient Analysis',\n",
    "        'variables': ['N (ppm)', 'P (ppm)', 'K (ppm)', 'Ca (ppm)', 'Mg (ppm)'],\n",
    "        'standardize': 'OPTIONAL',\n",
    "        'reason': 'Same units, but if nutrient ranges differ, standardize'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Crop Yield Analysis',\n",
    "        'variables': ['Wheat (kg/ha)', 'Corn (kg/ha)', 'Soy (kg/ha)'],\n",
    "        'standardize': 'DEPENDS',\n",
    "        'reason': 'Same units, but different crops have different yield ranges'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Weather Patterns',\n",
    "        'variables': ['Temp (Â°C)', 'Rainfall (mm)', 'Humidity (%)', 'Wind (km/h)'],\n",
    "        'standardize': 'YES âœ“',\n",
    "        'reason': 'Different units and scales - must standardize!'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"\\n{i}. {scenario['name']}\")\n",
    "    print(f\"   Variables: {', '.join(scenario['variables'])}\")\n",
    "    print(f\"   Standardize? {scenario['standardize']}\")\n",
    "    print(f\"   Reason: {scenario['reason']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nğŸ’¡ GOLDEN RULE: When in doubt, STANDARDIZE!\")\n",
    "print(\"   It's safer and ensures all variables contribute to PCA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary and Key Insights\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **The Problem**: Variables with different scales have different variances, causing some to dominate PCA\n",
    "\n",
    "2. **Z-Score Standardization** â­â­ (Most Important for PCA)\n",
    "   - Formula: $z = (x - \\mu) / \\sigma$\n",
    "   - Properties: Mean = 0, SD = 1\n",
    "   - Use for: PCA, most ML algorithms\n",
    "\n",
    "3. **Min-Max Normalization**\n",
    "   - Formula: $(x - \\text{min}) / (\\text{max} - \\text{min})$\n",
    "   - Properties: Range = 0 to 1\n",
    "   - Use for: Neural networks, bounded ranges\n",
    "\n",
    "4. **Robust Scaling**\n",
    "   - Formula: $(x - \\text{median}) / \\text{IQR}$\n",
    "   - Properties: Resistant to outliers\n",
    "   - Use for: Data with significant outliers\n",
    "\n",
    "5. **Impact on PCA**\n",
    "   - Covariance matrix PCA: Variables with larger variance dominate\n",
    "   - Correlation matrix PCA: All variables contribute equally\n",
    "   - Standardizing data â†’ PCA uses correlation matrix\n",
    "\n",
    "### Connection to PCA â­â­\n",
    "\n",
    "```python\n",
    "# WITHOUT standardization - WRONG for mixed units!\n",
    "cov_matrix = np.cov(soil_data.T)  # Nitrogen dominates\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# WITH standardization - CORRECT!\n",
    "soil_standardized = (soil_data - soil_data.mean()) / soil_data.std()\n",
    "cov_matrix_std = np.cov(soil_standardized.T)  # All variables equal\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix_std)\n",
    "```\n",
    "\n",
    "### Decision Framework for PCA\n",
    "\n",
    "```\n",
    "Are variables in different units? â”€â”€â”€â”€YESâ”€â”€â”€â”€> STANDARDIZE!\n",
    "         â”‚\n",
    "        NO\n",
    "         â”‚\n",
    "         â–¼\n",
    "Are variables on very different scales? â”€â”€YESâ”€â”€> STANDARDIZE!\n",
    "         â”‚\n",
    "        NO\n",
    "         â”‚\n",
    "         â–¼\n",
    "Do you want all variables to contribute equally? â”€â”€YESâ”€â”€> STANDARDIZE!\n",
    "         â”‚\n",
    "        NO\n",
    "         â”‚\n",
    "         â–¼\n",
    "   Can skip standardization (rare!)\n",
    "```\n",
    "\n",
    "### Agricultural Takeaways\n",
    "\n",
    "- ğŸŒ¾ Soil analysis: Different nutrients, pH, moisture â†’ **Always standardize**\n",
    "- ğŸŒ± Crop yields: Different crops with different ranges â†’ **Standardize**\n",
    "- â˜€ï¸ Weather data: Temperature, rainfall, humidity â†’ **Always standardize**\n",
    "- ğŸšœ Management practices: Different units and scales â†’ **Always standardize**\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll explore **data distributions** (skewness, kurtosis, normality) and understand how the shape of our data affects PCA and other analyses.\n",
    "\n",
    "You now have the essential preprocessing knowledge for PCA! In future notebooks, we'll:\n",
    "1. Explore data distributions\n",
    "2. Detect and handle outliers\n",
    "3. Apply these concepts to real agricultural datasets\n",
    "4. **Finally perform PCA** with properly prepared data!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Standardization is one of the most important preprocessing steps for PCA. When in doubt, standardize! ğŸ“Šâœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
