{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling and Sampling Distributions üåæüìä\n",
    "\n",
    "## Introduction: From Fields to Decisions\n",
    "\n",
    "Imagine you're an agricultural consultant managing 10,000 wheat fields across a region. You need to estimate the average yield to help farmers plan their marketing strategy. **You cannot physically measure all 10,000 fields** - it would be too expensive and time-consuming!\n",
    "\n",
    "**The Solution**: Take a **sample** of fields (say, 50), measure them carefully, and use that information to make conclusions about all 10,000 fields.\n",
    "\n",
    "This is the essence of **statistical inference**: using sample data to draw conclusions about populations.\n",
    "\n",
    "### Why This Matters for Machine Learning üéØ\n",
    "\n",
    "- **Cross-validation** is repeated sampling from your dataset\n",
    "- **Train/test splits** create samples for model evaluation\n",
    "- Understanding sampling variability helps you interpret model performance differences\n",
    "- Sample size determines reliability of your ML model evaluation\n",
    "\n",
    "**Key Question**: If we take different samples, we'll get different estimates. How do we quantify this uncertainty?\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives üéØ\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. ‚úÖ Understand the distinction between **population** and **sample**\n",
    "2. ‚úÖ Learn different **sampling methods** (random, stratified, systematic)\n",
    "3. ‚úÖ Grasp the concept of **sampling distributions** ‚≠ê‚≠ê\n",
    "4. ‚úÖ Calculate and interpret **standard error** (SE = œÉ/‚àön)\n",
    "5. ‚úÖ Understand **sampling variability** and its implications\n",
    "6. ‚úÖ Connect sampling concepts to **cross-validation in ML** ‚≠ê\n",
    "\n",
    "‚≠ê‚≠ê = Most critical concept\n",
    "\n",
    "---\n",
    "\n",
    "Let's begin! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Setup: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set style for beautiful plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Setup complete!\")\n",
    "print(\"üìä Ready to explore sampling and distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Population vs Sample üåç\n",
    "\n",
    "### Theory: The Foundation of Inference\n",
    "\n",
    "**Population**: The complete set of all individuals or observations we're interested in\n",
    "- Has true parameters: Œº (population mean), œÉ¬≤ (population variance)\n",
    "- Usually **unknown** and impossible to measure completely\n",
    "\n",
    "**Sample**: A subset of the population that we actually observe\n",
    "- Has sample statistics: xÃÑ (sample mean), s¬≤ (sample variance)\n",
    "- We use these to **estimate** population parameters\n",
    "\n",
    "### Mathematical Notation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Population Mean: } & \\mu = \\frac{1}{N}\\sum_{i=1}^{N} x_i \\\\\n",
    "\\text{Sample Mean: } & \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i \\\\\n",
    "\\text{Population Variance: } & \\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N} (x_i - \\mu)^2 \\\\\n",
    "\\text{Sample Variance: } & s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Note**: Sample variance uses (n-1) for unbiased estimation (Bessel's correction)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ Create a population of 10,000 wheat fields\n",
    "# True population: wheat yield ~ Normal(Œº=5.2 tons/hectare, œÉ=0.8)\n",
    "\n",
    "population_size = 10000\n",
    "population_mean = 5.2  # tons/hectare (true parameter Œº)\n",
    "population_std = 0.8   # tons/hectare (true parameter œÉ)\n",
    "\n",
    "# Generate the complete population\n",
    "population_yields = np.random.normal(population_mean, population_std, population_size)\n",
    "\n",
    "print(\"üåç POPULATION (All 10,000 fields)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"True Population Mean (Œº): {population_mean} tons/hectare\")\n",
    "print(f\"True Population Std Dev (œÉ): {population_std} tons/hectare\")\n",
    "print(f\"Actual Mean from simulation: {population_yields.mean():.3f} tons/hectare\")\n",
    "print(f\"Actual Std Dev from simulation: {population_yields.std(ddof=0):.3f} tons/hectare\")\n",
    "print(f\"\\nüí° In reality, we would NEVER know these true population parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 1: Population with sample overlays\n",
    "\n",
    "# Take 3 different samples of size n=50\n",
    "sample_size = 50\n",
    "sample1 = np.random.choice(population_yields, size=sample_size, replace=False)\n",
    "sample2 = np.random.choice(population_yields, size=sample_size, replace=False)\n",
    "sample3 = np.random.choice(population_yields, size=sample_size, replace=False)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot population distribution\n",
    "plt.hist(population_yields, bins=50, alpha=0.3, color='gray', \n",
    "         label=f'Population (N={population_size})', density=True, edgecolor='black')\n",
    "\n",
    "# Plot three sample distributions\n",
    "plt.hist(sample1, bins=15, alpha=0.5, color='red', \n",
    "         label=f'Sample 1 (n={sample_size}, xÃÑ={sample1.mean():.2f})', density=True)\n",
    "plt.hist(sample2, bins=15, alpha=0.5, color='blue', \n",
    "         label=f'Sample 2 (n={sample_size}, xÃÑ={sample2.mean():.2f})', density=True)\n",
    "plt.hist(sample3, bins=15, alpha=0.5, color='green', \n",
    "         label=f'Sample 3 (n={sample_size}, xÃÑ={sample3.mean():.2f})', density=True)\n",
    "\n",
    "# Mark the true population mean\n",
    "plt.axvline(population_mean, color='black', linestyle='--', linewidth=2, \n",
    "            label=f'True Œº = {population_mean}')\n",
    "\n",
    "plt.xlabel('Wheat Yield (tons/hectare)', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Population vs Samples: Different samples give different estimates! üåæ', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Observation:\")\n",
    "print(\"   - Each sample gives a slightly different mean (xÃÑ)\")\n",
    "print(\"   - All samples cluster around the true population mean (Œº)\")\n",
    "print(\"   - This variability is called SAMPLING VARIABILITY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Sampling Methods üé≤\n",
    "\n",
    "Not all samples are created equal! The **method** you use to select your sample affects the quality of your inference.\n",
    "\n",
    "### Common Sampling Methods:\n",
    "\n",
    "1. **Simple Random Sampling (SRS)** üéØ\n",
    "   - Every element has equal probability of selection\n",
    "   - Like drawing names from a hat\n",
    "   - ‚úÖ Best for homogeneous populations\n",
    "   - ‚ö†Ô∏è May miss important subgroups\n",
    "\n",
    "2. **Stratified Sampling** üìä\n",
    "   - Divide population into strata (groups), then sample from each\n",
    "   - Example: Sample from each soil type separately\n",
    "   - ‚úÖ Ensures representation of all subgroups\n",
    "   - ‚úÖ Often more efficient than SRS\n",
    "\n",
    "3. **Systematic Sampling** üìè\n",
    "   - Select every kth element (e.g., every 10th field in a row)\n",
    "   - ‚úÖ Simple to implement\n",
    "   - ‚ö†Ô∏è Beware of periodic patterns in data\n",
    "\n",
    "4. **Cluster Sampling** üó∫Ô∏è\n",
    "   - Divide population into clusters, randomly select entire clusters\n",
    "   - Example: Randomly select entire farms, measure all fields in selected farms\n",
    "   - ‚úÖ Cost-effective for geographically dispersed populations\n",
    "   - ‚ö†Ô∏è Less efficient than SRS (more variability)\n",
    "\n",
    "### ML Connection:\n",
    "- **Train/test split** = Simple random sampling\n",
    "- **Stratified K-fold CV** = Stratified sampling (ensures class balance)\n",
    "- **Time series CV** = Systematic sampling considerations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ Create a more complex population with different soil types (strata)\n",
    "# 3 soil types: Clay (40%), Loam (50%), Sand (10%)\n",
    "\n",
    "# Generate stratified population\n",
    "n_clay = 4000\n",
    "n_loam = 5000\n",
    "n_sand = 1000\n",
    "\n",
    "# Different yield distributions for each soil type\n",
    "clay_yields = np.random.normal(5.5, 0.6, n_clay)  # Higher mean, lower variability\n",
    "loam_yields = np.random.normal(5.2, 0.7, n_loam)  # Medium mean\n",
    "sand_yields = np.random.normal(4.5, 1.0, n_sand)  # Lower mean, higher variability\n",
    "\n",
    "# Combine into a DataFrame\n",
    "population_df = pd.DataFrame({\n",
    "    'yield': np.concatenate([clay_yields, loam_yields, sand_yields]),\n",
    "    'soil_type': ['Clay']*n_clay + ['Loam']*n_loam + ['Sand']*n_sand,\n",
    "    'field_id': range(10000)\n",
    "})\n",
    "\n",
    "print(\"üåç Population Composition:\")\n",
    "print(\"=\" * 50)\n",
    "print(population_df.groupby('soil_type')['yield'].agg(['count', 'mean', 'std']))\n",
    "print(f\"\\nOverall Population Mean: {population_df['yield'].mean():.3f} tons/hectare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ Implement different sampling methods\n",
    "\n",
    "sample_size = 200\n",
    "\n",
    "# 1. Simple Random Sampling\n",
    "srs_sample = population_df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# 2. Stratified Sampling (proportional allocation)\n",
    "stratified_sample = population_df.groupby('soil_type', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=sample_size/len(population_df), random_state=42)\n",
    ")\n",
    "\n",
    "# 3. Systematic Sampling (every 50th field)\n",
    "k = len(population_df) // sample_size\n",
    "start = np.random.randint(0, k)\n",
    "systematic_indices = range(start, len(population_df), k)\n",
    "systematic_sample = population_df.iloc[list(systematic_indices)[:sample_size]]\n",
    "\n",
    "# 4. Cluster Sampling (select 20 random \"farms\" of 10 fields each)\n",
    "population_df['farm_id'] = population_df['field_id'] // 10  # Create farm clusters\n",
    "selected_farms = np.random.choice(population_df['farm_id'].unique(), size=20, replace=False)\n",
    "cluster_sample = population_df[population_df['farm_id'].isin(selected_farms)]\n",
    "\n",
    "# Compare estimates\n",
    "true_mean = population_df['yield'].mean()\n",
    "\n",
    "print(\"\\nüìä Sampling Method Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True Population Mean: {true_mean:.3f} tons/hectare\")\n",
    "print(f\"Simple Random Sampling:  {srs_sample['yield'].mean():.3f} (error: {abs(srs_sample['yield'].mean() - true_mean):.3f})\")\n",
    "print(f\"Stratified Sampling:     {stratified_sample['yield'].mean():.3f} (error: {abs(stratified_sample['yield'].mean() - true_mean):.3f})\")\n",
    "print(f\"Systematic Sampling:     {systematic_sample['yield'].mean():.3f} (error: {abs(systematic_sample['yield'].mean() - true_mean):.3f})\")\n",
    "print(f\"Cluster Sampling:        {cluster_sample['yield'].mean():.3f} (error: {abs(cluster_sample['yield'].mean() - true_mean):.3f})\")\n",
    "print(\"\\nüí° Stratified sampling often gives the most accurate estimate!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 2: Comparing sampling methods\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Comparison of Sampling Methods üé≤', fontsize=16, fontweight='bold', y=1.00)\n",
    "\n",
    "# Helper function to plot samples\n",
    "def plot_sample_by_soil(ax, sample_df, title, true_mean):\n",
    "    soil_colors = {'Clay': '#8B4513', 'Loam': '#D2691E', 'Sand': '#F4A460'}\n",
    "    \n",
    "    for soil in ['Clay', 'Loam', 'Sand']:\n",
    "        soil_data = sample_df[sample_df['soil_type'] == soil]['yield']\n",
    "        ax.hist(soil_data, bins=15, alpha=0.6, label=f'{soil} (n={len(soil_data)})',\n",
    "                color=soil_colors[soil], edgecolor='black')\n",
    "    \n",
    "    sample_mean = sample_df['yield'].mean()\n",
    "    ax.axvline(true_mean, color='black', linestyle='--', linewidth=2, label=f'True Œº={true_mean:.2f}')\n",
    "    ax.axvline(sample_mean, color='red', linestyle='-', linewidth=2, label=f'Sample xÃÑ={sample_mean:.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Yield (tons/hectare)', fontsize=10)\n",
    "    ax.set_ylabel('Frequency', fontsize=10)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot each sampling method\n",
    "plot_sample_by_soil(axes[0, 0], srs_sample, '1. Simple Random Sampling', true_mean)\n",
    "plot_sample_by_soil(axes[0, 1], stratified_sample, '2. Stratified Sampling ‚úÖ', true_mean)\n",
    "plot_sample_by_soil(axes[1, 0], systematic_sample, '3. Systematic Sampling', true_mean)\n",
    "plot_sample_by_soil(axes[1, 1], cluster_sample, '4. Cluster Sampling', true_mean)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Notice:\")\n",
    "print(\"   - Stratified sampling best represents all soil types\")\n",
    "print(\"   - Cluster sampling has more variability (fewer unique locations)\")\n",
    "print(\"   - This affects the accuracy of our population estimate!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Sampling Distribution ‚≠ê‚≠ê\n",
    "\n",
    "### The Most Important Concept in Statistical Inference!\n",
    "\n",
    "**Sampling Distribution**: The distribution of a sample statistic (like xÃÑ) across many possible samples\n",
    "\n",
    "**Key Idea**: \n",
    "- If we take ONE sample ‚Üí we get ONE estimate (xÃÑ)\n",
    "- If we take MANY samples ‚Üí we get MANY estimates (xÃÑ‚ÇÅ, xÃÑ‚ÇÇ, xÃÑ‚ÇÉ, ...)\n",
    "- The distribution of these estimates is the **sampling distribution**\n",
    "\n",
    "### Standard Error (SE):\n",
    "\n",
    "The standard deviation of the sampling distribution is called the **standard error**:\n",
    "\n",
    "$$\n",
    "SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- œÉ = population standard deviation\n",
    "- n = sample size\n",
    "\n",
    "**Key Insight**: Standard error decreases with ‚àön, not n!\n",
    "- To cut SE in half, you need 4√ó the sample size\n",
    "- To cut SE by 1/10, you need 100√ó the sample size\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ Simulate the sampling distribution\n",
    "# Take 1000 different samples, calculate mean for each\n",
    "\n",
    "n_simulations = 1000\n",
    "sample_size = 50\n",
    "sample_means = []\n",
    "\n",
    "# Simulate taking many samples\n",
    "for i in range(n_simulations):\n",
    "    sample = np.random.choice(population_yields, size=sample_size, replace=False)\n",
    "    sample_means.append(sample.mean())\n",
    "\n",
    "sample_means = np.array(sample_means)\n",
    "\n",
    "# Calculate theoretical vs empirical standard error\n",
    "theoretical_se = population_std / np.sqrt(sample_size)\n",
    "empirical_se = sample_means.std()\n",
    "\n",
    "print(\"üéØ Sampling Distribution of Sample Means:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True Population Mean (Œº): {population_mean:.3f} tons/hectare\")\n",
    "print(f\"Mean of sample means: {sample_means.mean():.3f} tons/hectare\")\n",
    "print(f\"\\nTheoretical SE = œÉ/‚àön = {population_std:.3f}/‚àö{sample_size} = {theoretical_se:.3f}\")\n",
    "print(f\"Empirical SE (from simulation): {empirical_se:.3f}\")\n",
    "print(f\"\\nüí° The sample means cluster around the true Œº with spread = SE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 3: The sampling distribution\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot the sampling distribution\n",
    "plt.hist(sample_means, bins=40, alpha=0.7, color='steelblue', \n",
    "         edgecolor='black', density=True, label=f'{n_simulations} sample means')\n",
    "\n",
    "# Overlay theoretical normal distribution\n",
    "x = np.linspace(sample_means.min(), sample_means.max(), 100)\n",
    "plt.plot(x, stats.norm.pdf(x, population_mean, theoretical_se), \n",
    "         'r-', linewidth=2, label=f'Theoretical: N(Œº={population_mean}, SE={theoretical_se:.3f})')\n",
    "\n",
    "# Mark the true population mean\n",
    "plt.axvline(population_mean, color='black', linestyle='--', linewidth=2, \n",
    "            label=f'True Œº = {population_mean}')\n",
    "\n",
    "# Mark ¬±1 SE and ¬±2 SE\n",
    "plt.axvline(population_mean - theoretical_se, color='green', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "plt.axvline(population_mean + theoretical_se, color='green', linestyle=':', linewidth=1.5, alpha=0.7, \n",
    "            label='¬±1 SE (68% of samples)')\n",
    "plt.axvline(population_mean - 2*theoretical_se, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n",
    "plt.axvline(population_mean + 2*theoretical_se, color='orange', linestyle=':', linewidth=1.5, alpha=0.7,\n",
    "            label='¬±2 SE (95% of samples)')\n",
    "\n",
    "plt.xlabel('Sample Mean xÃÑ (tons/hectare)', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title(f'Sampling Distribution: Distribution of {n_simulations} Sample Means (n={sample_size}) üìä', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='upper left', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Observations:\")\n",
    "print(\"   - Sample means follow a NORMAL distribution (we'll see why in next notebook!)\")\n",
    "print(\"   - Distribution is centered at the true Œº\")\n",
    "print(\"   - Spread is determined by SE = œÉ/‚àön\")\n",
    "print(\"   - About 95% of sample means fall within ¬±2 SE of true Œº\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Effect of sample size on sampling distribution\n",
    "# Compare n = 5, 10, 25, 50, 100, 200\n",
    "\n",
    "sample_sizes = [5, 10, 25, 50, 100, 200]\n",
    "n_sims = 1000\n",
    "\n",
    "sampling_distributions = {}\n",
    "\n",
    "for n in sample_sizes:\n",
    "    means = []\n",
    "    for _ in range(n_sims):\n",
    "        sample = np.random.choice(population_yields, size=n, replace=False)\n",
    "        means.append(sample.mean())\n",
    "    sampling_distributions[n] = np.array(means)\n",
    "\n",
    "# Calculate theoretical SEs\n",
    "theoretical_ses = {n: population_std / np.sqrt(n) for n in sample_sizes}\n",
    "\n",
    "print(\"üìè Effect of Sample Size on Standard Error:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Sample Size (n)':<15} {'Theoretical SE':<20} {'Empirical SE':<20}\")\n",
    "print(\"-\" * 60)\n",
    "for n in sample_sizes:\n",
    "    theoretical = theoretical_ses[n]\n",
    "    empirical = sampling_distributions[n].std()\n",
    "    print(f\"{n:<15} {theoretical:<20.4f} {empirical:<20.4f}\")\n",
    "\n",
    "print(\"\\nüí° Notice: SE decreases as ‚àön, so doubling n doesn't halve SE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 4: Effect of sample size (6-panel comparison)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.ravel()\n",
    "fig.suptitle('Effect of Sample Size on Sampling Distribution üìè', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot sampling distribution\n",
    "    ax.hist(sampling_distributions[n], bins=30, alpha=0.7, color='steelblue', \n",
    "            edgecolor='black', density=True)\n",
    "    \n",
    "    # Overlay theoretical normal\n",
    "    x = np.linspace(sampling_distributions[n].min(), \n",
    "                    sampling_distributions[n].max(), 100)\n",
    "    ax.plot(x, stats.norm.pdf(x, population_mean, theoretical_ses[n]), \n",
    "            'r-', linewidth=2)\n",
    "    \n",
    "    # Mark true mean\n",
    "    ax.axvline(population_mean, color='black', linestyle='--', linewidth=1.5)\n",
    "    \n",
    "    # Add text box with SE\n",
    "    textstr = f'n = {n}\\nSE = {theoretical_ses[n]:.3f}'\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "    ax.text(0.70, 0.95, textstr, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props)\n",
    "    \n",
    "    ax.set_xlabel('Sample Mean', fontsize=10)\n",
    "    ax.set_ylabel('Density', fontsize=10)\n",
    "    ax.set_title(f'Sample Size n = {n}', fontsize=11, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Observation:\")\n",
    "print(\"   - Larger n ‚Üí Narrower sampling distribution ‚Üí More precise estimates!\")\n",
    "print(\"   - Distribution gets tighter around true Œº as n increases\")\n",
    "print(\"   - This is why larger samples give more reliable results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Sampling Variability and Standard Error üìä\n",
    "\n",
    "**Sampling Variability**: The fact that different samples give different estimates\n",
    "\n",
    "**Standard Error (SE)**: Quantifies the typical amount of sampling variability\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "When you report xÃÑ = 5.15 tons/hectare, you should also report the **uncertainty**:\n",
    "- \"xÃÑ = 5.15 ¬± 0.11\" (mean ¬± SE)\n",
    "- This acknowledges that a different sample would give a different estimate\n",
    "\n",
    "### Practical Interpretation:\n",
    "\n",
    "- **Small SE**: Sample estimate is close to population parameter (reliable)\n",
    "- **Large SE**: High uncertainty in estimate (need larger sample)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ Demonstrate sampling variability\n",
    "# Take 20 samples, show the range of estimates\n",
    "\n",
    "n_samples = 20\n",
    "sample_size = 50\n",
    "estimates = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    sample = np.random.choice(population_yields, size=sample_size, replace=False)\n",
    "    estimates.append(sample.mean())\n",
    "\n",
    "estimates = np.array(estimates)\n",
    "\n",
    "# Calculate SE\n",
    "se = population_std / np.sqrt(sample_size)\n",
    "\n",
    "print(\"üéØ Sampling Variability Demonstration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True Population Mean (Œº): {population_mean:.3f} tons/hectare\")\n",
    "print(f\"\\n{n_samples} Sample Estimates:\")\n",
    "print(\"-\" * 60)\n",
    "for i, est in enumerate(estimates, 1):\n",
    "    print(f\"Sample {i:2d}: xÃÑ = {est:.3f} tons/hectare (error: {abs(est - population_mean):.3f})\")\n",
    "\n",
    "print(f\"\\nRange of estimates: [{estimates.min():.3f}, {estimates.max():.3f}]\")\n",
    "print(f\"Standard deviation of estimates: {estimates.std():.3f}\")\n",
    "print(f\"Theoretical SE: {se:.3f}\")\n",
    "print(f\"\\nüí° Different samples ‚Üí different estimates! SE quantifies this variability.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 5: Range of estimates with ¬±2SE bands\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot each estimate as a point\n",
    "plt.scatter(range(1, n_samples+1), estimates, s=100, alpha=0.7, \n",
    "            color='steelblue', edgecolors='black', linewidths=1.5, zorder=3)\n",
    "\n",
    "# Draw lines from each point to the true mean\n",
    "for i, est in enumerate(estimates, 1):\n",
    "    plt.plot([i, i], [population_mean, est], 'gray', alpha=0.3, linewidth=1)\n",
    "\n",
    "# Mark the true population mean\n",
    "plt.axhline(population_mean, color='black', linestyle='--', linewidth=2, \n",
    "            label=f'True Œº = {population_mean:.2f}', zorder=2)\n",
    "\n",
    "# Draw ¬±2 SE bands (95% of estimates should fall here)\n",
    "plt.axhline(population_mean + 2*se, color='red', linestyle=':', linewidth=1.5, \n",
    "            alpha=0.7, label=f'Œº ¬± 2SE', zorder=1)\n",
    "plt.axhline(population_mean - 2*se, color='red', linestyle=':', linewidth=1.5, \n",
    "            alpha=0.7, zorder=1)\n",
    "plt.fill_between(range(1, n_samples+1), population_mean - 2*se, \n",
    "                 population_mean + 2*se, alpha=0.1, color='red')\n",
    "\n",
    "# Count how many fall within ¬±2SE\n",
    "within_2se = np.sum((estimates >= population_mean - 2*se) & \n",
    "                    (estimates <= population_mean + 2*se))\n",
    "\n",
    "plt.xlabel('Sample Number', fontsize=12)\n",
    "plt.ylabel('Sample Mean (tons/hectare)', fontsize=12)\n",
    "plt.title(f'Sampling Variability: {n_samples} Different Samples (n={sample_size}) üé≤', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.xlim(0, n_samples+1)\n",
    "\n",
    "# Add annotation\n",
    "plt.text(n_samples*0.5, population_mean + 2.5*se, \n",
    "         f'{within_2se}/{n_samples} estimates within ¬±2SE (expected: ~{int(0.95*n_samples)})',\n",
    "         fontsize=11, ha='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"   - Each dot is the mean from one sample\")\n",
    "print(\"   - Most estimates cluster around the true Œº\")\n",
    "print(f\"   - About 95% fall within ¬±2SE = ¬±{2*se:.3f} of true Œº\")\n",
    "print(\"   - This is the foundation of confidence intervals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Machine Learning Connection ‚≠ê\n",
    "\n",
    "### Cross-Validation is Repeated Sampling!\n",
    "\n",
    "When you perform **k-fold cross-validation**:\n",
    "1. You split your data into k subsets\n",
    "2. Train on k-1 subsets, test on 1 subset\n",
    "3. Repeat k times ‚Üí get k different accuracy scores\n",
    "\n",
    "**This is exactly sampling!** Each train/test split is a different \"sample\" from your data.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Different splits ‚Üí different scores** (sampling variability!)\n",
    "2. **Report mean ¬± SE** of CV scores (not just mean)\n",
    "3. **Larger training sets** ‚Üí lower variance in model performance (SE decreases with ‚àön)\n",
    "4. **Understand variability** ‚Üí know when performance differences are meaningful\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "- Model A: 85% ¬± 2% accuracy\n",
    "- Model B: 84% ¬± 5% accuracy\n",
    "\n",
    "Is Model A better? The higher SE in Model B means **higher uncertainty**. The difference might not be real!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ ML Example: Train/test split variability\n",
    "# Create a classification dataset: Predict if yield > 5.0 tons/hectare\n",
    "\n",
    "# Generate features and labels\n",
    "np.random.seed(42)\n",
    "X = np.column_stack([\n",
    "    np.random.normal(7.0, 1.5, 1000),  # soil_nitrogen\n",
    "    np.random.normal(6.5, 0.8, 1000),  # soil_pH\n",
    "    np.random.normal(150, 30, 1000),   # rainfall_mm\n",
    "])\n",
    "\n",
    "# Create target: high yield if conditions are good\n",
    "yield_score = (0.3 * X[:, 0] + 0.2 * X[:, 1] + 0.005 * X[:, 2] + \n",
    "               np.random.normal(0, 0.5, 1000))\n",
    "y = (yield_score > 5.0).astype(int)\n",
    "\n",
    "print(\"üåæ Agricultural Classification Problem:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Features: soil_nitrogen, soil_pH, rainfall_mm\")\n",
    "print(f\"Target: high_yield (1 if yield > 5.0 tons/hectare, else 0)\")\n",
    "print(f\"Dataset size: {len(X)} observations\")\n",
    "print(f\"Class distribution: {np.sum(y)} high yield, {len(y) - np.sum(y)} low yield\")\n",
    "print(f\"\\nüí° We'll train a logistic regression model with different train/test splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ Demonstrate train/test split variability\n",
    "# Train the same model 30 times with different random splits\n",
    "\n",
    "n_splits = 30\n",
    "test_size = 0.2\n",
    "accuracy_scores = []\n",
    "\n",
    "for seed in range(n_splits):\n",
    "    # Different random split each time\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "accuracy_scores = np.array(accuracy_scores)\n",
    "\n",
    "# Calculate statistics\n",
    "mean_accuracy = accuracy_scores.mean()\n",
    "se_accuracy = accuracy_scores.std()  # Empirical SE\n",
    "\n",
    "print(\"ü§ñ Model Performance Variability:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of different train/test splits: {n_splits}\")\n",
    "print(f\"Training set size: {len(X_train)} observations\")\n",
    "print(f\"Test set size: {len(X_test)} observations\")\n",
    "print(f\"\\nAccuracy across {n_splits} splits:\")\n",
    "print(f\"  Mean: {mean_accuracy:.4f}\")\n",
    "print(f\"  Std Dev (SE): {se_accuracy:.4f}\")\n",
    "print(f\"  Min: {accuracy_scores.min():.4f}\")\n",
    "print(f\"  Max: {accuracy_scores.max():.4f}\")\n",
    "print(f\"  Range: {accuracy_scores.max() - accuracy_scores.min():.4f}\")\n",
    "print(f\"\\nüí° Report as: Accuracy = {mean_accuracy:.2%} ¬± {se_accuracy:.2%}\")\n",
    "print(\"   This acknowledges the variability due to different train/test splits!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 6: Distribution of accuracy scores\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(accuracy_scores, vert=True, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "            medianprops=dict(color='red', linewidth=2),\n",
    "            whiskerprops=dict(linewidth=1.5),\n",
    "            capprops=dict(linewidth=1.5))\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Box Plot of Accuracy Scores', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks([1], [f'{n_splits} splits'])\n",
    "\n",
    "# Add text annotations\n",
    "plt.text(1.35, mean_accuracy, f'Mean = {mean_accuracy:.4f}\\nSE = {se_accuracy:.4f}',\n",
    "         fontsize=10, va='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(accuracy_scores, bins=15, alpha=0.7, color='steelblue', \n",
    "         edgecolor='black', density=True)\n",
    "\n",
    "# Overlay normal distribution\n",
    "x = np.linspace(accuracy_scores.min(), accuracy_scores.max(), 100)\n",
    "plt.plot(x, stats.norm.pdf(x, mean_accuracy, se_accuracy), \n",
    "         'r-', linewidth=2, label='Normal fit')\n",
    "\n",
    "plt.axvline(mean_accuracy, color='black', linestyle='--', linewidth=2, \n",
    "            label=f'Mean = {mean_accuracy:.4f}')\n",
    "plt.axvline(mean_accuracy - 2*se_accuracy, color='green', linestyle=':', \n",
    "            linewidth=1.5, alpha=0.7)\n",
    "plt.axvline(mean_accuracy + 2*se_accuracy, color='green', linestyle=':', \n",
    "            linewidth=1.5, alpha=0.7, label='¬±2 SE')\n",
    "\n",
    "plt.xlabel('Accuracy', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Distribution of Accuracy Scores', fontsize=12, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ML Model Performance Variability Due to Train/Test Split ü§ñ', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   - Model performance VARIES depending on which data points are in train vs test\")\n",
    "print(\"   - This is sampling variability in action!\")\n",
    "print(\"   - Always report uncertainty (SE or confidence intervals)\")\n",
    "print(\"   - Cross-validation provides multiple samples ‚Üí better estimate of true performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Wrap-Up: Agricultural Applications üåæ\n",
    "\n",
    "### Where Sampling Matters in Agriculture:\n",
    "\n",
    "1. **Soil Testing** üß™\n",
    "   - Cannot test every location in a field\n",
    "   - Take strategic samples (grid, stratified by zone)\n",
    "   - Estimate mean nutrient levels with confidence intervals\n",
    "\n",
    "2. **Yield Estimation** üìä\n",
    "   - Cannot harvest and weigh entire fields before harvest\n",
    "   - Sample plots to estimate total yield\n",
    "   - SE tells you reliability of estimate\n",
    "\n",
    "3. **Quality Control** ‚úÖ\n",
    "   - Cannot inspect every fruit/grain\n",
    "   - Sample batches to estimate defect rate\n",
    "   - Determine appropriate sample size for desired precision\n",
    "\n",
    "4. **Field Trials** üß™\n",
    "   - Test new varieties or treatments\n",
    "   - Each field is a sample from all possible fields\n",
    "   - Understand variability in treatment effects\n",
    "\n",
    "5. **ML Model Evaluation** ü§ñ\n",
    "   - Each train/test split is a sample\n",
    "   - Cross-validation creates multiple samples\n",
    "   - Report performance with uncertainty bounds\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways üéØ\n",
    "\n",
    "### Core Concepts:\n",
    "\n",
    "1. ‚úÖ **Population vs Sample**: \n",
    "   - Population has parameters (Œº, œÉ) - usually unknown\n",
    "   - Sample has statistics (xÃÑ, s) - used to estimate parameters\n",
    "\n",
    "2. ‚úÖ **Sampling Methods**: \n",
    "   - Simple random: Equal probability for all\n",
    "   - Stratified: Sample from each group (often best for heterogeneous populations)\n",
    "   - Systematic: Every kth element\n",
    "   - Cluster: Sample entire groups\n",
    "\n",
    "3. ‚úÖ **Sampling Distribution** ‚≠ê‚≠ê:\n",
    "   - Distribution of sample statistics across many samples\n",
    "   - Centered at the true population parameter\n",
    "   - Spread measured by standard error (SE)\n",
    "\n",
    "4. ‚úÖ **Standard Error**:\n",
    "   - SE = œÉ/‚àön\n",
    "   - Quantifies typical sampling variability\n",
    "   - Decreases with ‚àön (not n!)\n",
    "\n",
    "5. ‚úÖ **Sampling Variability**:\n",
    "   - Different samples ‚Üí different estimates\n",
    "   - About 95% of samples fall within ¬±2 SE of true parameter\n",
    "   - Foundation of confidence intervals\n",
    "\n",
    "6. ‚úÖ **ML Connection** ‚≠ê:\n",
    "   - Cross-validation is repeated sampling\n",
    "   - Train/test splits create sampling variability\n",
    "   - Always report model performance with SE or CI\n",
    "   - Larger training sets ‚Üí lower performance variance\n",
    "\n",
    "### Critical Formula:\n",
    "\n",
    "$$\n",
    "\\boxed{SE = \\frac{\\sigma}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "This single formula governs how uncertainty decreases with sample size!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps üöÄ\n",
    "\n",
    "**Coming Up Next: Central Limit Theorem** ‚≠ê‚≠ê\n",
    "\n",
    "You've seen that sampling distributions look approximately normal. But why?\n",
    "\n",
    "In the next notebook, we'll discover the **Central Limit Theorem** - the most important theorem in statistics:\n",
    "\n",
    "- Why sample means are (almost) always normal\n",
    "- Works for ANY population distribution!\n",
    "- Foundation of all statistical inference\n",
    "- **Why ensemble methods work in ML**\n",
    "\n",
    "**Questions to think about**:\n",
    "1. What if the population is highly skewed? Will sample means still be normal?\n",
    "2. How large does n need to be for normality?\n",
    "3. What does this have to do with bootstrap and bagging?\n",
    "\n",
    "All will be answered in **`02_central_limit_theorem.ipynb`**!\n",
    "\n",
    "---\n",
    "\n",
    "**Great work! You've mastered the foundations of sampling and sampling distributions.** üåæüìä‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
