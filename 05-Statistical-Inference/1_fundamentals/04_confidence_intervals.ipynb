{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals: Quantifying Uncertainty üìä\n",
    "\n",
    "## Introduction: From Point to Interval\n",
    "\n",
    "In the previous notebook, we learned **point estimation**: Using sample data to estimate a parameter with a single number.\n",
    "\n",
    "**Example**: Sample mean = 5.15 tons/hectare\n",
    "\n",
    "But this doesn't tell the whole story! **How certain are we about this estimate?**\n",
    "\n",
    "### The Problem with Point Estimates:\n",
    "\n",
    "- Different samples give different estimates (sampling variability)\n",
    "- A single number doesn't convey uncertainty\n",
    "- We need a **range of plausible values**\n",
    "\n",
    "### The Solution: Confidence Intervals! üéØ\n",
    "\n",
    "Instead of saying: **\"ŒºÃÇ = 5.15\"**\n",
    "\n",
    "We say: **\"ŒºÃÇ = 5.15, 95% CI: [5.02, 5.28]\"**\n",
    "\n",
    "This communicates:\n",
    "- Our best estimate (5.15)\n",
    "- Our uncertainty (¬±0.13)\n",
    "- Our confidence level (95%)\n",
    "\n",
    "### ML Connection ü§ñ\n",
    "\n",
    "**Always report ML model performance with confidence intervals!**\n",
    "\n",
    "Bad: \"Model accuracy = 85%\"\n",
    "\n",
    "Good: \"Model accuracy = 85% ¬± 2% (95% CI: [83%, 87%])\"\n",
    "\n",
    "The second tells you how reliable the performance estimate is!\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives üéØ\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. ‚úÖ Understand the **confidence interval concept** ‚≠ê‚≠ê\n",
    "2. ‚úÖ Calculate CI for mean (œÉ known and unknown)\n",
    "3. ‚úÖ Calculate CI for proportions\n",
    "4. ‚úÖ **Interpret confidence levels correctly** (most critical!)\n",
    "5. ‚úÖ Understand factors affecting CI width\n",
    "6. ‚úÖ Apply to ML: **Model performance with uncertainty** ‚≠ê‚≠ê\n",
    "\n",
    "‚≠ê‚≠ê = Most critical concept\n",
    "\n",
    "---\n",
    "\n",
    "Let's quantify uncertainty! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Setup: Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Set style for beautiful plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úì Setup complete!\")\n",
    "print(\"üìä Ready to learn confidence intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Confidence Interval Intuition üí°\n",
    "\n",
    "### What is a Confidence Interval?\n",
    "\n",
    "**General Form**:\n",
    "\n",
    "$$\n",
    "\\text{CI} = \\text{Point Estimate} \\pm \\text{Margin of Error}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{CI} = \\hat{\\theta} \\pm (\\text{Critical Value}) \\times SE(\\hat{\\theta})\n",
    "$$\n",
    "\n",
    "### For Sample Mean:\n",
    "\n",
    "$$\n",
    "\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- xÃÑ = sample mean (point estimate)\n",
    "- z* = critical value (e.g., 1.96 for 95% confidence)\n",
    "- œÉ/‚àön = standard error (uncertainty in estimate)\n",
    "\n",
    "### CRITICAL INTERPRETATION ‚ö†Ô∏è\n",
    "\n",
    "**WRONG**: \"There is a 95% probability that Œº is in [a, b]\"\n",
    "\n",
    "**CORRECT**: \"If we repeat this procedure many times, 95% of the intervals will contain the true Œº\"\n",
    "\n",
    "The parameter Œº is **fixed** (not random). The interval is **random** (changes with different samples).\n",
    "\n",
    "### Confidence Level:\n",
    "\n",
    "- **90% CI**: 90% of such intervals will capture true parameter\n",
    "- **95% CI**: 95% of such intervals will capture true parameter (most common)\n",
    "- **99% CI**: 99% of such intervals will capture true parameter\n",
    "\n",
    "Higher confidence ‚Üí Wider interval (trade-off!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ Simulation: Demonstrate CI interpretation\n",
    "# Take 100 samples, construct 95% CI for each, see how many capture true Œº\n",
    "\n",
    "# True population\n",
    "true_mu = 5.2\n",
    "true_sigma = 0.8\n",
    "population = np.random.normal(true_mu, true_sigma, 100000)\n",
    "\n",
    "# Simulation parameters\n",
    "n_intervals = 100\n",
    "sample_size = 50\n",
    "confidence_level = 0.95\n",
    "z_star = stats.norm.ppf((1 + confidence_level) / 2)  # 1.96 for 95%\n",
    "\n",
    "# Store CI information\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "captures_mu = []\n",
    "\n",
    "for _ in range(n_intervals):\n",
    "    # Take a sample\n",
    "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "    \n",
    "    # Calculate 95% CI (assuming œÉ known for simplicity)\n",
    "    x_bar = sample.mean()\n",
    "    se = true_sigma / np.sqrt(sample_size)\n",
    "    margin = z_star * se\n",
    "    \n",
    "    lower = x_bar - margin\n",
    "    upper = x_bar + margin\n",
    "    \n",
    "    ci_lower.append(lower)\n",
    "    ci_upper.append(upper)\n",
    "    captures_mu.append(lower <= true_mu <= upper)\n",
    "\n",
    "ci_lower = np.array(ci_lower)\n",
    "ci_upper = np.array(ci_upper)\n",
    "captures_mu = np.array(captures_mu)\n",
    "\n",
    "capture_rate = captures_mu.mean()\n",
    "\n",
    "print(\"üéØ Confidence Interval Interpretation Simulation:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True population mean: Œº = {true_mu}\")\n",
    "print(f\"Confidence level: {confidence_level*100}%\")\n",
    "print(f\"Number of intervals constructed: {n_intervals}\")\n",
    "print(f\"\\nRESULTS:\")\n",
    "print(f\"  Intervals that captured true Œº: {captures_mu.sum()}/{n_intervals}\")\n",
    "print(f\"  Capture rate: {capture_rate*100:.1f}%\")\n",
    "print(f\"  Expected: ~{confidence_level*100:.0f}%\")\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   '{confidence_level*100:.0f}% confidence' means:\")\n",
    "print(f\"   If we repeat this procedure many times, {confidence_level*100:.0f}% of intervals\")\n",
    "print(f\"   will contain the true parameter Œº\")\n",
    "print(f\"\\n‚ö†Ô∏è It does NOT mean 'Œº has {confidence_level*100:.0f}% probability of being in this interval'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 1: The famous CI interpretation plot\n",
    "# 100 horizontal lines (CIs), green if captures Œº, red if doesn't\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot each CI as a horizontal line\n",
    "for i in range(n_intervals):\n",
    "    color = 'green' if captures_mu[i] else 'red'\n",
    "    alpha = 0.6 if captures_mu[i] else 0.9\n",
    "    linewidth = 1 if captures_mu[i] else 2\n",
    "    \n",
    "    # Horizontal line from lower to upper\n",
    "    plt.plot([ci_lower[i], ci_upper[i]], [i, i], color=color, \n",
    "             alpha=alpha, linewidth=linewidth)\n",
    "    \n",
    "    # Mark the point estimate\n",
    "    point_est = (ci_lower[i] + ci_upper[i]) / 2\n",
    "    plt.scatter([point_est], [i], color=color, s=20, alpha=alpha, zorder=3)\n",
    "\n",
    "# Mark the true parameter\n",
    "plt.axvline(true_mu, color='blue', linestyle='--', linewidth=3, \n",
    "            label=f'True Œº = {true_mu}', zorder=2)\n",
    "\n",
    "plt.xlabel('Wheat Yield (tons/hectare)', fontsize=12)\n",
    "plt.ylabel('Sample Number', fontsize=12)\n",
    "plt.title(f'Confidence Interval Interpretation: {n_intervals} Different 95% CIs üéØ', \n",
    "          fontsize=14, fontweight='bold')\n",
    "\n",
    "# Custom legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='blue', linestyle='--', linewidth=3, label=f'True Œº = {true_mu}'),\n",
    "    Line2D([0], [0], color='green', linewidth=2, label=f'Captures Œº ({captures_mu.sum()})'),\n",
    "    Line2D([0], [0], color='red', linewidth=2, label=f'Misses Œº ({n_intervals - captures_mu.sum()})')\n",
    "]\n",
    "plt.legend(handles=legend_elements, fontsize=11, loc='upper right')\n",
    "\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.xlim(4.5, 6.0)\n",
    "\n",
    "# Add text box\n",
    "textstr = f'Capture Rate: {capture_rate*100:.1f}%\\nExpected: {confidence_level*100:.0f}%'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=12,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° What This Plot Shows:\")\n",
    "print(\"   - Each horizontal line is a 95% CI from a different sample\")\n",
    "print(\"   - GREEN lines: CI contains true Œº ‚úì\")\n",
    "print(\"   - RED lines: CI misses true Œº ‚úó\")\n",
    "print(f\"   - About {confidence_level*100:.0f}% are green (as expected!)\")\n",
    "print(\"\\nüí° Correct Interpretation:\")\n",
    "print(\"   'The procedure captures Œº 95% of the time'\")\n",
    "print(\"   NOT 'Œº is in this specific interval with 95% probability'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. CI for Mean (œÉ Known) üìè\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "Rarely in practice (we usually don't know œÉ), but useful for understanding concepts.\n",
    "\n",
    "### Formula:\n",
    "\n",
    "$$\n",
    "\\bar{x} \\pm z^* \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "### Critical Values (z*):\n",
    "\n",
    "| Confidence Level | z* |\n",
    "|-----------------|----|\n",
    "| 90% | 1.645 |\n",
    "| 95% | 1.960 |\n",
    "| 99% | 2.576 |\n",
    "\n",
    "### Trade-off:\n",
    "\n",
    "- **Higher confidence** ‚Üí Larger z* ‚Üí **Wider interval** (less precise)\n",
    "- **Lower confidence** ‚Üí Smaller z* ‚Üí **Narrower interval** (more precise)\n",
    "\n",
    "You can't have high confidence AND high precision simultaneously!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ Calculate CIs with different confidence levels\n",
    "\n",
    "# Sample data\n",
    "np.random.seed(42)\n",
    "sample_size = 50\n",
    "sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "x_bar = sample.mean()\n",
    "sigma = true_sigma  # Assume known\n",
    "se = sigma / np.sqrt(sample_size)\n",
    "\n",
    "# Calculate CIs for different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "cis = {}\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    z_star = stats.norm.ppf((1 + conf) / 2)\n",
    "    margin = z_star * se\n",
    "    lower = x_bar - margin\n",
    "    upper = x_bar + margin\n",
    "    cis[conf] = (lower, upper, margin, z_star)\n",
    "\n",
    "print(\"üìè Confidence Intervals with Different Confidence Levels:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {sample_size}\")\n",
    "print(f\"Sample mean: xÃÑ = {x_bar:.3f} tons/hectare\")\n",
    "print(f\"Population œÉ (assumed known): {sigma}\")\n",
    "print(f\"Standard Error: SE = œÉ/‚àön = {se:.4f}\")\n",
    "print(f\"\\n{'Confidence':<12} {'z*':<8} {'Margin':<12} {'CI':<30}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    lower, upper, margin, z_star = cis[conf]\n",
    "    print(f\"{conf*100:.0f}%{'':<9} {z_star:<8.3f} {margin:<12.4f} [{lower:.3f}, {upper:.3f}]\")\n",
    "\n",
    "print(\"\\nüí° Notice the trade-off:\")\n",
    "print(\"   - Higher confidence ‚Üí Wider interval (less precise)\")\n",
    "print(\"   - Lower confidence ‚Üí Narrower interval (more precise)\")\n",
    "print(\"   - You must choose based on your needs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 2: Confidence vs Precision trade-off\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot CIs as horizontal lines\n",
    "colors = ['orange', 'green', 'blue']\n",
    "y_positions = [3, 2, 1]\n",
    "\n",
    "for idx, conf in enumerate(confidence_levels):\n",
    "    lower, upper, margin, z_star = cis[conf]\n",
    "    y = y_positions[idx]\n",
    "    \n",
    "    # Draw CI\n",
    "    plt.plot([lower, upper], [y, y], color=colors[idx], linewidth=4, \n",
    "             label=f'{conf*100:.0f}% CI: [{lower:.2f}, {upper:.2f}]')\n",
    "    \n",
    "    # Mark endpoints\n",
    "    plt.scatter([lower, upper], [y, y], color=colors[idx], s=100, \n",
    "                edgecolors='black', linewidths=1.5, zorder=3)\n",
    "    \n",
    "    # Mark point estimate\n",
    "    plt.scatter([x_bar], [y], color='red', s=150, marker='D', \n",
    "                edgecolors='black', linewidths=1.5, zorder=4)\n",
    "\n",
    "# Mark true parameter\n",
    "plt.axvline(true_mu, color='black', linestyle='--', linewidth=2, alpha=0.7,\n",
    "            label=f'True Œº = {true_mu}')\n",
    "\n",
    "plt.xlabel('Wheat Yield (tons/hectare)', fontsize=12)\n",
    "plt.yticks(y_positions, [f'{c*100:.0f}% Confidence' for c in confidence_levels])\n",
    "plt.title('Confidence vs Precision Trade-off üìä', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "plt.xlim(4.7, 5.7)\n",
    "\n",
    "# Annotations\n",
    "plt.annotate('', xy=(cis[0.99][0], 0.5), xytext=(cis[0.99][1], 0.5),\n",
    "             arrowprops=dict(arrowstyle='<->', lw=2, color='blue'))\n",
    "plt.text((cis[0.99][0] + cis[0.99][1])/2, 0.3, 'Wider\\n(less precise)', \n",
    "         ha='center', fontsize=10, color='blue', fontweight='bold')\n",
    "\n",
    "plt.annotate('', xy=(cis[0.90][0], 3.5), xytext=(cis[0.90][1], 3.5),\n",
    "             arrowprops=dict(arrowstyle='<->', lw=2, color='orange'))\n",
    "plt.text((cis[0.90][0] + cis[0.90][1])/2, 3.7, 'Narrower\\n(more precise)', \n",
    "         ha='center', fontsize=10, color='orange', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   - All three CIs contain the true Œº (in this case)\")\n",
    "print(\"   - But 99% CI is much wider than 90% CI\")\n",
    "print(\"   - Choose confidence level based on consequences of being wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. CI for Mean (œÉ Unknown) ‚≠ê‚≠ê\n",
    "\n",
    "### The Realistic Case\n",
    "\n",
    "In practice, we **don't know œÉ**! We must estimate it from the sample: s\n",
    "\n",
    "### Problem:\n",
    "\n",
    "Using s instead of œÉ introduces additional uncertainty\n",
    "\n",
    "### Solution: t-Distribution!\n",
    "\n",
    "$$\n",
    "\\bar{x} \\pm t^*_{df} \\times \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- t* = critical value from t-distribution\n",
    "- df = n - 1 (degrees of freedom)\n",
    "- s = sample standard deviation\n",
    "\n",
    "### t vs z Distribution:\n",
    "\n",
    "- **t-distribution**: Heavier tails, accounts for uncertainty in estimating œÉ\n",
    "- As n ‚Üí ‚àû, t-distribution ‚Üí normal distribution\n",
    "- For n ‚â• 30, t and z are very similar\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "- ‚úÖ **Use t**: When œÉ is unknown (almost always!)\n",
    "- Use z: Only when œÉ is truly known (rare)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ Calculate CI using t-distribution (œÉ unknown)\n",
    "\n",
    "# Sample data (same as before)\n",
    "x_bar = sample.mean()\n",
    "s = sample.std(ddof=1)  # Sample SD (unbiased)\n",
    "n = len(sample)\n",
    "se = s / np.sqrt(n)\n",
    "\n",
    "# 95% CI using t-distribution\n",
    "confidence = 0.95\n",
    "df = n - 1\n",
    "t_star = stats.t.ppf((1 + confidence) / 2, df)\n",
    "z_star = stats.norm.ppf((1 + confidence) / 2)\n",
    "\n",
    "margin_t = t_star * se\n",
    "margin_z = z_star * se\n",
    "\n",
    "ci_t = (x_bar - margin_t, x_bar + margin_t)\n",
    "ci_z = (x_bar - margin_z, x_bar + margin_z)\n",
    "\n",
    "print(\"üìä Confidence Interval with Unknown œÉ (Using t-distribution):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(f\"Degrees of freedom: df = {df}\")\n",
    "print(f\"Sample mean: xÃÑ = {x_bar:.4f} tons/hectare\")\n",
    "print(f\"Sample SD: s = {s:.4f}\")\n",
    "print(f\"Standard Error: SE = s/‚àön = {se:.4f}\")\n",
    "print(f\"\\nCRITICAL VALUES (95% confidence):\")\n",
    "print(f\"  t* (df={df}) = {t_star:.4f}\")\n",
    "print(f\"  z* = {z_star:.4f}\")\n",
    "print(f\"  Difference: t* is {(t_star/z_star - 1)*100:.1f}% larger\")\n",
    "print(f\"\\n95% CONFIDENCE INTERVALS:\")\n",
    "print(f\"  Using t-distribution: [{ci_t[0]:.4f}, {ci_t[1]:.4f}]\")\n",
    "print(f\"  Using z-distribution: [{ci_z[0]:.4f}, {ci_z[1]:.4f}]\")\n",
    "print(f\"\\nüí° The t-distribution gives a slightly wider interval\")\n",
    "print(f\"   to account for uncertainty in estimating œÉ with s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 3: t vs z distributions\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: PDF comparison\n",
    "x = np.linspace(-4, 4, 200)\n",
    "dfs = [5, 10, 30, 100]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(dfs)))\n",
    "\n",
    "for df, color in zip(dfs, colors):\n",
    "    axes[0].plot(x, stats.t.pdf(x, df), color=color, linewidth=2, \n",
    "                 label=f't (df={df})', alpha=0.7)\n",
    "\n",
    "axes[0].plot(x, stats.norm.pdf(x), 'r--', linewidth=2.5, label='z (Normal)')\n",
    "axes[0].set_xlabel('Value', fontsize=11)\n",
    "axes[0].set_ylabel('Density', fontsize=11)\n",
    "axes[0].set_title('t-distribution vs Normal Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Critical values convergence\n",
    "df_range = range(1, 101)\n",
    "t_crits = [stats.t.ppf(0.975, df) for df in df_range]\n",
    "z_crit = stats.norm.ppf(0.975)\n",
    "\n",
    "axes[1].plot(df_range, t_crits, 'b-', linewidth=2, label='t* (df)')\n",
    "axes[1].axhline(z_crit, color='r', linestyle='--', linewidth=2, label=f'z* = {z_crit:.3f}')\n",
    "axes[1].axvline(30, color='green', linestyle=':', linewidth=1.5, alpha=0.7,\n",
    "                label='df=30 (rule of thumb)')\n",
    "axes[1].set_xlabel('Degrees of Freedom (df)', fontsize=11)\n",
    "axes[1].set_ylabel('Critical Value (95% CI)', fontsize=11)\n",
    "axes[1].set_title('Convergence: t* ‚Üí z* as df Increases', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(0, 100)\n",
    "\n",
    "plt.suptitle('Understanding the t-Distribution üìä', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Observations:\")\n",
    "print(\"   - t-distribution has heavier tails than normal (more probability in extremes)\")\n",
    "print(\"   - As df increases, t-distribution ‚Üí normal distribution\")\n",
    "print(\"   - For df ‚â• 30, t and z are practically identical\")\n",
    "print(\"   - Always use t when œÉ is unknown (safest choice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìè Effect of sample size on CI width\n",
    "# Demonstrate that CI width ‚àù 1/‚àön\n",
    "\n",
    "sample_sizes = [10, 25, 50, 100, 200, 500]\n",
    "ci_widths = []\n",
    "theoretical_widths = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    # Take a sample\n",
    "    sample = np.random.choice(population, size=n, replace=False)\n",
    "    \n",
    "    # Calculate 95% CI\n",
    "    x_bar = sample.mean()\n",
    "    s = sample.std(ddof=1)\n",
    "    se = s / np.sqrt(n)\n",
    "    t_star = stats.t.ppf(0.975, n-1)\n",
    "    margin = t_star * se\n",
    "    \n",
    "    width = 2 * margin\n",
    "    ci_widths.append(width)\n",
    "    \n",
    "    # Theoretical width (assuming œÉ known)\n",
    "    theoretical_width = 2 * 1.96 * true_sigma / np.sqrt(n)\n",
    "    theoretical_widths.append(theoretical_width)\n",
    "\n",
    "print(\"üìè Effect of Sample Size on CI Width:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'n':<8} {'CI Width':<12} {'Theoretical':<15} {'Improvement'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for idx, n in enumerate(sample_sizes):\n",
    "    if idx == 0:\n",
    "        improvement = \"baseline\"\n",
    "    else:\n",
    "        improvement = f\"{ci_widths[0]/ci_widths[idx]:.2f}√ó narrower\"\n",
    "    \n",
    "    print(f\"{n:<8} {ci_widths[idx]:<12.4f} {theoretical_widths[idx]:<15.4f} {improvement}\")\n",
    "\n",
    "print(\"\\nüí° To cut CI width in half, you need 4√ó the sample size!\")\n",
    "print(\"   (Because SE ‚àù 1/‚àön)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 4: CI width vs sample size\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot CI width vs n\n",
    "plt.plot(sample_sizes, ci_widths, 'bo-', linewidth=2, markersize=10, \n",
    "         label='Observed CI Width', alpha=0.7)\n",
    "plt.plot(sample_sizes, theoretical_widths, 'r--', linewidth=2, \n",
    "         label='Theoretical (œÉ known)', alpha=0.7)\n",
    "\n",
    "# Add reference line showing 1/‚àön relationship\n",
    "reference = [ci_widths[0] * np.sqrt(sample_sizes[0]/n) for n in sample_sizes]\n",
    "plt.plot(sample_sizes, reference, 'g:', linewidth=2, alpha=0.5,\n",
    "         label='1/‚àön reference')\n",
    "\n",
    "plt.xlabel('Sample Size (n)', fontsize=12)\n",
    "plt.ylabel('95% CI Width', fontsize=12)\n",
    "plt.title('CI Width Decreases with ‚àön üìè', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "for i, n in enumerate(sample_sizes[::2]):\n",
    "    idx = i * 2\n",
    "    plt.annotate(f'n={n}\\nwidth={ci_widths[idx]:.2f}', \n",
    "                 xy=(n, ci_widths[idx]), \n",
    "                 xytext=(n, ci_widths[idx] + 0.1),\n",
    "                 fontsize=9, ha='center',\n",
    "                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.6))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   - CI width is proportional to 1/‚àön\")\n",
    "print(\"   - Diminishing returns: Going from n=10 to n=100 helps a lot\")\n",
    "print(\"   - But going from n=100 to n=1000 helps much less\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. CI for Proportions üìä\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "Estimating population proportion (e.g., germination rate, disease incidence, defect rate)\n",
    "\n",
    "### Formula:\n",
    "\n",
    "$$\n",
    "\\hat{p} \\pm z^* \\times \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- pÃÇ = sample proportion\n",
    "- SE = ‚àö[pÃÇ(1-pÃÇ)/n]\n",
    "\n",
    "### Requirements:\n",
    "\n",
    "- npÃÇ ‚â• 10 and n(1-pÃÇ) ‚â• 10 (for normal approximation)\n",
    "\n",
    "### Example:\n",
    "\n",
    "Out of 200 seeds, 176 germinated ‚Üí pÃÇ = 0.88\n",
    "\n",
    "What's the 95% CI for germination rate?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üå± CI for proportion: Seed germination rate\n",
    "\n",
    "# Data\n",
    "n_seeds = 200\n",
    "n_germinated = 176\n",
    "p_hat = n_germinated / n_seeds\n",
    "\n",
    "# Check requirements\n",
    "check1 = n_seeds * p_hat\n",
    "check2 = n_seeds * (1 - p_hat)\n",
    "\n",
    "print(\"üå± Confidence Interval for Seed Germination Rate:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {n_seeds} seeds\")\n",
    "print(f\"Germinated: {n_germinated} seeds\")\n",
    "print(f\"Sample proportion: pÃÇ = {p_hat:.4f} ({p_hat*100:.1f}%)\")\n",
    "print(f\"\\nRequirement checks (need both ‚â• 10):\")\n",
    "print(f\"  npÃÇ = {check1:.1f} ‚úì\" if check1 >= 10 else f\"  npÃÇ = {check1:.1f} ‚úó\")\n",
    "print(f\"  n(1-pÃÇ) = {check2:.1f} ‚úì\" if check2 >= 10 else f\"  n(1-pÃÇ) = {check2:.1f} ‚úó\")\n",
    "\n",
    "# Calculate 95% CI\n",
    "se = np.sqrt(p_hat * (1 - p_hat) / n_seeds)\n",
    "z_star = stats.norm.ppf(0.975)\n",
    "margin = z_star * se\n",
    "\n",
    "ci_lower = p_hat - margin\n",
    "ci_upper = p_hat + margin\n",
    "\n",
    "print(f\"\\n95% CONFIDENCE INTERVAL:\")\n",
    "print(f\"  Standard Error: SE = ‚àö[pÃÇ(1-pÃÇ)/n] = {se:.4f}\")\n",
    "print(f\"  Margin of Error: z* √ó SE = {margin:.4f}\")\n",
    "print(f\"  CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "print(f\"  CI: [{ci_lower*100:.1f}%, {ci_upper*100:.1f}%]\")\n",
    "print(f\"\\nüí° Interpretation:\")\n",
    "print(f\"   We are 95% confident that the true germination rate\")\n",
    "print(f\"   is between {ci_lower*100:.1f}% and {ci_upper*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 5: CI for proportion on number line\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Number line\n",
    "plt.plot([0, 1], [0, 0], 'k-', linewidth=2, alpha=0.3)\n",
    "\n",
    "# CI as thick line\n",
    "plt.plot([ci_lower, ci_upper], [0, 0], 'b-', linewidth=8, alpha=0.6, \n",
    "         label=f'95% CI: [{ci_lower*100:.1f}%, {ci_upper*100:.1f}%]')\n",
    "\n",
    "# Point estimate\n",
    "plt.scatter([p_hat], [0], s=300, c='red', marker='D', zorder=5, \n",
    "            edgecolors='black', linewidths=2, label=f'pÃÇ = {p_hat*100:.1f}%')\n",
    "\n",
    "# Endpoints\n",
    "plt.scatter([ci_lower, ci_upper], [0, 0], s=200, c='blue', marker='|', \n",
    "            zorder=4, linewidths=3)\n",
    "\n",
    "# Annotations\n",
    "plt.text(p_hat, 0.08, f'Sample: {n_germinated}/{n_seeds}\\ngerminated', \n",
    "         ha='center', fontsize=10,\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.xlabel('Germination Rate', fontsize=12)\n",
    "plt.xticks(np.arange(0, 1.1, 0.1), [f'{x*100:.0f}%' for x in np.arange(0, 1.1, 0.1)])\n",
    "plt.yticks([])\n",
    "plt.title('95% Confidence Interval for Germination Rate üå±', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='upper left')\n",
    "plt.xlim(0.75, 0.98)\n",
    "plt.ylim(-0.15, 0.15)\n",
    "plt.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° For agricultural decision-making:\")\n",
    "print(f\"   If you need ‚â•85% germination rate, you can be confident this\")\n",
    "print(f\"   seed lot meets the requirement (lower bound = {ci_lower*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Factors Affecting CI Width üìè\n",
    "\n",
    "Three main factors determine confidence interval width:\n",
    "\n",
    "### 1. Sample Size (n) ‚≠ê\n",
    "\n",
    "- Larger n ‚Üí Smaller SE ‚Üí **Narrower CI** (more precise)\n",
    "- Width ‚àù 1/‚àön\n",
    "- Most controllable factor!\n",
    "\n",
    "### 2. Confidence Level ‚≠ê\n",
    "\n",
    "- Higher confidence ‚Üí Larger critical value ‚Üí **Wider CI**\n",
    "- 90% CI narrower than 95% CI narrower than 99% CI\n",
    "- Trade-off: confidence vs precision\n",
    "\n",
    "### 3. Population Variability (œÉ) ‚≠ê\n",
    "\n",
    "- More variability ‚Üí Larger SE ‚Üí **Wider CI**\n",
    "- Can't control, but can measure\n",
    "\n",
    "### Formula Breakdown:\n",
    "\n",
    "$$\n",
    "\\text{Width} = 2 \\times z^* \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "- z* depends on confidence level\n",
    "- œÉ depends on population variability\n",
    "- ‚àön is the sample size factor\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ Systematic exploration of factors affecting CI width\n",
    "\n",
    "# Base case\n",
    "base_n = 50\n",
    "base_conf = 0.95\n",
    "base_sigma = 0.8\n",
    "\n",
    "# Calculate base width\n",
    "base_z = stats.norm.ppf((1 + base_conf) / 2)\n",
    "base_width = 2 * base_z * base_sigma / np.sqrt(base_n)\n",
    "\n",
    "print(\"üî¨ Factors Affecting Confidence Interval Width:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"BASE CASE: n={base_n}, confidence={base_conf*100:.0f}%, œÉ={base_sigma}\")\n",
    "print(f\"Base CI width: {base_width:.4f}\")\n",
    "\n",
    "# Factor 1: Sample size\n",
    "print(f\"\\n1. EFFECT OF SAMPLE SIZE (confidence={base_conf*100:.0f}%, œÉ={base_sigma}):\")\n",
    "for n in [25, 50, 100, 200]:\n",
    "    width = 2 * base_z * base_sigma / np.sqrt(n)\n",
    "    ratio = width / base_width\n",
    "    print(f\"   n={n:3d}: width={width:.4f} ({ratio:.2f}√ó base width)\")\n",
    "\n",
    "# Factor 2: Confidence level\n",
    "print(f\"\\n2. EFFECT OF CONFIDENCE LEVEL (n={base_n}, œÉ={base_sigma}):\")\n",
    "for conf in [0.90, 0.95, 0.99]:\n",
    "    z = stats.norm.ppf((1 + conf) / 2)\n",
    "    width = 2 * z * base_sigma / np.sqrt(base_n)\n",
    "    ratio = width / base_width\n",
    "    print(f\"   {conf*100:.0f}%: width={width:.4f} ({ratio:.2f}√ó base width)\")\n",
    "\n",
    "# Factor 3: Population variability\n",
    "print(f\"\\n3. EFFECT OF VARIABILITY (n={base_n}, confidence={base_conf*100:.0f}%):\")\n",
    "for sigma in [0.4, 0.8, 1.2, 1.6]:\n",
    "    width = 2 * base_z * sigma / np.sqrt(base_n)\n",
    "    ratio = width / base_width\n",
    "    print(f\"   œÉ={sigma:.1f}: width={width:.4f} ({ratio:.2f}√ó base width)\")\n",
    "\n",
    "print(\"\\nüí° Key Insights:\")\n",
    "print(\"   - Doubling n cuts width by ‚àö2 ‚âà 1.41 (diminishing returns)\")\n",
    "print(\"   - Higher confidence ‚Üí wider interval (trade-off)\")\n",
    "print(\"   - More variable population ‚Üí wider interval (can't control)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 6: Three-panel showing each factor's effect\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Panel 1: Sample size effect\n",
    "sample_sizes_viz = np.arange(10, 201, 5)\n",
    "widths_n = [2 * base_z * base_sigma / np.sqrt(n) for n in sample_sizes_viz]\n",
    "\n",
    "axes[0].plot(sample_sizes_viz, widths_n, 'b-', linewidth=2)\n",
    "axes[0].scatter([base_n], [base_width], s=200, c='red', marker='*', \n",
    "                zorder=5, edgecolors='black', linewidths=1.5,\n",
    "                label=f'Base: n={base_n}')\n",
    "axes[0].set_xlabel('Sample Size (n)', fontsize=11)\n",
    "axes[0].set_ylabel('CI Width', fontsize=11)\n",
    "axes[0].set_title('Effect of Sample Size\\n(larger n ‚Üí narrower CI)', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: Confidence level effect\n",
    "confs = np.linspace(0.80, 0.99, 50)\n",
    "widths_conf = [2 * stats.norm.ppf((1 + c) / 2) * base_sigma / np.sqrt(base_n) \n",
    "               for c in confs]\n",
    "\n",
    "axes[1].plot(confs * 100, widths_conf, 'g-', linewidth=2)\n",
    "axes[1].scatter([base_conf * 100], [base_width], s=200, c='red', marker='*', \n",
    "                zorder=5, edgecolors='black', linewidths=1.5,\n",
    "                label=f'Base: {base_conf*100:.0f}%')\n",
    "axes[1].set_xlabel('Confidence Level (%)', fontsize=11)\n",
    "axes[1].set_ylabel('CI Width', fontsize=11)\n",
    "axes[1].set_title('Effect of Confidence Level\\n(higher confidence ‚Üí wider CI)', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: Variability effect\n",
    "sigmas = np.linspace(0.2, 2.0, 50)\n",
    "widths_sigma = [2 * base_z * s / np.sqrt(base_n) for s in sigmas]\n",
    "\n",
    "axes[2].plot(sigmas, widths_sigma, 'orange', linewidth=2)\n",
    "axes[2].scatter([base_sigma], [base_width], s=200, c='red', marker='*', \n",
    "                zorder=5, edgecolors='black', linewidths=1.5,\n",
    "                label=f'Base: œÉ={base_sigma}')\n",
    "axes[2].set_xlabel('Population Std Dev (œÉ)', fontsize=11)\n",
    "axes[2].set_ylabel('CI Width', fontsize=11)\n",
    "axes[2].set_title('Effect of Variability\\n(higher œÉ ‚Üí wider CI)', \n",
    "                  fontsize=11, fontweight='bold')\n",
    "axes[2].legend(fontsize=9)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Factors Affecting Confidence Interval Width üìè', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Which factor can you control?\")\n",
    "print(\"   - Sample size (n): YES! ‚úì Most practical way to get narrower CIs\")\n",
    "print(\"   - Confidence level: YES, but involves trade-offs\")\n",
    "print(\"   - Variability (œÉ): NO, it's a property of the population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. One-Sided Confidence Intervals üìä\n",
    "\n",
    "### When to Use:\n",
    "\n",
    "Sometimes we only care about one direction:\n",
    "\n",
    "- **Upper bound**: \"Is the defect rate less than 5%?\"\n",
    "- **Lower bound**: \"Is yield greater than 4.5 tons/hectare?\"\n",
    "\n",
    "### One-Sided CI:\n",
    "\n",
    "**Lower bound** (\"at least\"):\n",
    "$$\n",
    "\\bar{x} - z^* \\times SE < \\mu\n",
    "$$\n",
    "\n",
    "**Upper bound** (\"at most\"):\n",
    "$$\n",
    "\\mu < \\bar{x} + z^* \\times SE\n",
    "$$\n",
    "\n",
    "### Critical Values:\n",
    "\n",
    "For 95% one-sided CI: z* = 1.645 (not 1.96!)\n",
    "\n",
    "### Example:\n",
    "\n",
    "Pesticide effectiveness: We want to show it reduces pests by **at least** X%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üêõ One-sided CI: Pesticide effectiveness\n",
    "# Question: What's the minimum reduction in pests we can be confident about?\n",
    "\n",
    "# Data: Pest reduction (percentage)\n",
    "np.random.seed(42)\n",
    "n = 40\n",
    "pest_reduction = np.random.normal(65, 12, n)  # Mean 65% reduction, SD 12%\n",
    "\n",
    "x_bar = pest_reduction.mean()\n",
    "s = pest_reduction.std(ddof=1)\n",
    "se = s / np.sqrt(n)\n",
    "\n",
    "# Two-sided 95% CI\n",
    "t_two_sided = stats.t.ppf(0.975, n-1)\n",
    "ci_two_lower = x_bar - t_two_sided * se\n",
    "ci_two_upper = x_bar + t_two_sided * se\n",
    "\n",
    "# One-sided 95% CI (lower bound)\n",
    "t_one_sided = stats.t.ppf(0.95, n-1)  # 0.95, not 0.975!\n",
    "ci_one_lower = x_bar - t_one_sided * se\n",
    "\n",
    "print(\"üêõ Pesticide Effectiveness - One-Sided CI:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sample size: n = {n} treated fields\")\n",
    "print(f\"Mean pest reduction: {x_bar:.2f}%\")\n",
    "print(f\"Sample SD: {s:.2f}%\")\n",
    "print(f\"Standard Error: {se:.2f}%\")\n",
    "print(f\"\\nCRITICAL VALUES (95% confidence):\")\n",
    "print(f\"  Two-sided: t* = {t_two_sided:.3f}\")\n",
    "print(f\"  One-sided: t* = {t_one_sided:.3f}\")\n",
    "print(f\"\\n95% TWO-SIDED CI:\")\n",
    "print(f\"  [{ci_two_lower:.2f}%, {ci_two_upper:.2f}%]\")\n",
    "print(f\"  Interpretation: Œº is between {ci_two_lower:.1f}% and {ci_two_upper:.1f}%\")\n",
    "print(f\"\\n95% ONE-SIDED CI (LOWER BOUND):\")\n",
    "print(f\"  {ci_one_lower:.2f}% < Œº\")\n",
    "print(f\"  Interpretation: Reduction is AT LEAST {ci_one_lower:.1f}%\")\n",
    "print(f\"\\nüí° Use one-sided when you only care about one direction!\")\n",
    "print(f\"   Here: We want to guarantee MINIMUM effectiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 7: One-sided vs two-sided CI\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Two-sided CI\n",
    "axes[0].plot([ci_two_lower, ci_two_upper], [0, 0], 'b-', linewidth=8, alpha=0.6)\n",
    "axes[0].scatter([x_bar], [0], s=300, c='red', marker='D', zorder=5, \n",
    "                edgecolors='black', linewidths=2)\n",
    "axes[0].scatter([ci_two_lower, ci_two_upper], [0, 0], s=200, c='blue', \n",
    "                marker='|', zorder=4, linewidths=3)\n",
    "axes[0].set_xlabel('Pest Reduction (%)', fontsize=11)\n",
    "axes[0].set_yticks([])\n",
    "axes[0].set_title('Two-Sided 95% CI\\n(estimate range)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlim(50, 80)\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "axes[0].text(x_bar, 0.08, f'[{ci_two_lower:.1f}%, {ci_two_upper:.1f}%]',\n",
    "             ha='center', fontsize=10,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "# Right: One-sided CI (lower bound)\n",
    "axes[1].arrow(ci_one_lower, 0, 15, 0, head_width=0.04, head_length=1.5, \n",
    "              fc='green', ec='darkgreen', linewidth=2, alpha=0.6)\n",
    "axes[1].scatter([x_bar], [0], s=300, c='red', marker='D', zorder=5, \n",
    "                edgecolors='black', linewidths=2)\n",
    "axes[1].scatter([ci_one_lower], [0], s=200, c='green', marker='|', \n",
    "                zorder=4, linewidths=3)\n",
    "axes[1].set_xlabel('Pest Reduction (%)', fontsize=11)\n",
    "axes[1].set_yticks([])\n",
    "axes[1].set_title('One-Sided 95% CI (Lower Bound)\\n(minimum guarantee)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlim(50, 80)\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "axes[1].text(ci_one_lower + 7, 0.08, f'‚â• {ci_one_lower:.1f}%',\n",
    "             ha='center', fontsize=11, fontweight='bold',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "\n",
    "plt.suptitle('One-Sided vs Two-Sided Confidence Intervals üìä', \n",
    "             fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° When to use one-sided:\")\n",
    "print(\"   - Regulatory compliance: 'At most X% defects'\")\n",
    "print(\"   - Minimum performance: 'At least Y% effectiveness'\")\n",
    "print(\"   - Only care about one direction of deviation\")\n",
    "print(f\"\\nüìä For this pesticide:\")\n",
    "print(f\"   We can claim with 95% confidence that it reduces pests by\")\n",
    "print(f\"   AT LEAST {ci_one_lower:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Machine Learning Connection ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "### Always Report Model Performance with CIs!\n",
    "\n",
    "**Bad Practice**: \"Model accuracy = 85%\"\n",
    "\n",
    "**Good Practice**: \"Model accuracy = 85% ¬± 2% (95% CI: [83%, 87%])\"\n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "1. **Quantifies Uncertainty**: Is 85% really different from 83%?\n",
    "2. **Helps Model Comparison**: If CIs overlap, performance may not be truly different\n",
    "3. **Reflects Sample Size**: Larger test sets ‚Üí narrower CIs ‚Üí more reliable estimates\n",
    "\n",
    "### Methods:\n",
    "\n",
    "1. **Normal Approximation** (for large test sets):\n",
    "   $$\n",
    "   \\text{accuracy} \\pm z^* \\times \\sqrt{\\frac{\\text{acc}(1-\\text{acc})}{n}}\n",
    "   $$\n",
    "\n",
    "2. **Bootstrap CI** (more robust, works for any metric):\n",
    "   - Resample test set with replacement\n",
    "   - Calculate metric for each resample\n",
    "   - Use percentiles of bootstrap distribution\n",
    "\n",
    "### Cross-Validation:\n",
    "\n",
    "K-fold CV gives you K scores ‚Üí calculate mean ¬± CI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ü§ñ ML Example: Model performance with CI\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Generate agricultural classification data\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(n_samples=500, n_features=10, n_informative=8,\n",
    "                          n_redundant=2, random_state=42)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                      random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test set accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = (y_pred == y_test).mean()\n",
    "n_test = len(y_test)\n",
    "\n",
    "# Calculate 95% CI for accuracy (normal approximation)\n",
    "se = np.sqrt(accuracy * (1 - accuracy) / n_test)\n",
    "z_star = 1.96\n",
    "margin = z_star * se\n",
    "ci_lower = accuracy - margin\n",
    "ci_upper = accuracy + margin\n",
    "\n",
    "print(\"ü§ñ ML Model Performance with Confidence Interval:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: {X.shape[0]} agricultural observations, {X.shape[1]} features\")\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"\\nMODEL PERFORMANCE:\")\n",
    "print(f\"  Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Standard Error: {se:.4f}\")\n",
    "print(f\"  95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "print(f\"  95% CI: [{ci_lower*100:.2f}%, {ci_upper*100:.2f}%]\")\n",
    "print(f\"\\n‚úÖ PROPER REPORTING:\")\n",
    "print(f\"   'Model accuracy = {accuracy*100:.1f}% ¬± {margin*100:.1f}%'\")\n",
    "print(f\"   '95% CI: [{ci_lower*100:.1f}%, {ci_upper*100:.1f}%]'\")\n",
    "print(f\"\\n‚ùå IMPROPER REPORTING:\")\n",
    "print(f\"   'Model accuracy = {accuracy*100:.1f}%' (no uncertainty!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Cross-validation with confidence intervals\n",
    "\n",
    "# Perform 10-fold CV\n",
    "cv_scores = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and CI\n",
    "cv_mean = cv_scores.mean()\n",
    "cv_std = cv_scores.std()\n",
    "cv_se = cv_std / np.sqrt(len(cv_scores))\n",
    "\n",
    "# 95% CI using t-distribution\n",
    "t_star = stats.t.ppf(0.975, len(cv_scores) - 1)\n",
    "cv_margin = t_star * cv_se\n",
    "cv_ci_lower = cv_mean - cv_margin\n",
    "cv_ci_upper = cv_mean + cv_margin\n",
    "\n",
    "print(\"üîÑ Cross-Validation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"10-fold CV scores:\")\n",
    "print(f\"  {cv_scores.round(4)}\")\n",
    "print(f\"\\nSUMMARY STATISTICS:\")\n",
    "print(f\"  Mean accuracy: {cv_mean:.4f} ({cv_mean*100:.2f}%)\")\n",
    "print(f\"  Std deviation: {cv_std:.4f}\")\n",
    "print(f\"  Standard error: {cv_se:.4f}\")\n",
    "print(f\"  95% CI: [{cv_ci_lower:.4f}, {cv_ci_upper:.4f}]\")\n",
    "print(f\"  95% CI: [{cv_ci_lower*100:.2f}%, {cv_ci_upper*100:.2f}%]\")\n",
    "print(f\"\\nüí° This gives us confidence in the model's true performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visualization 8: CV scores distribution with CI\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histogram of CV scores\n",
    "plt.hist(cv_scores, bins=8, alpha=0.7, color='steelblue', \n",
    "         edgecolor='black', density=True, label='CV Scores')\n",
    "\n",
    "# Mark mean\n",
    "plt.axvline(cv_mean, color='red', linestyle='-', linewidth=2, \n",
    "            label=f'Mean = {cv_mean:.3f}')\n",
    "\n",
    "# Mark CI\n",
    "plt.axvline(cv_ci_lower, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "plt.axvline(cv_ci_upper, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "plt.axvspan(cv_ci_lower, cv_ci_upper, alpha=0.2, color='green', \n",
    "            label=f'95% CI: [{cv_ci_lower:.3f}, {cv_ci_upper:.3f}]')\n",
    "\n",
    "# Overlay normal distribution\n",
    "x = np.linspace(cv_scores.min() - 0.02, cv_scores.max() + 0.02, 100)\n",
    "plt.plot(x, stats.norm.pdf(x, cv_mean, cv_std), 'orange', linewidth=2, \n",
    "         alpha=0.7, label='Normal fit')\n",
    "\n",
    "plt.xlabel('Accuracy', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.title('Cross-Validation Scores Distribution with 95% CI üîÑ', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add text box\n",
    "textstr = f'10-Fold CV\\nMean: {cv_mean:.3f}\\n95% CI: [{cv_ci_lower:.3f}, {cv_ci_upper:.3f}]'\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)\n",
    "plt.text(0.02, 0.98, textstr, transform=plt.gca().transAxes, fontsize=11,\n",
    "         verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Proper ML Reporting:\")\n",
    "print(f\"   'Our model achieves {cv_mean*100:.1f}% accuracy'\")\n",
    "print(f\"   '(95% CI: [{cv_ci_lower*100:.1f}%, {cv_ci_upper*100:.1f}%])'\")\n",
    "print(f\"   'based on 10-fold cross-validation'\")\n",
    "print(f\"\\nüéØ This communicates both performance AND uncertainty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways üéØ\n",
    "\n",
    "### Confidence Intervals:\n",
    "\n",
    "1. ‚úÖ **Definition**:\n",
    "   - CI = Point Estimate ¬± Margin of Error\n",
    "   - CI = Œ∏ÃÇ ¬± (Critical Value) √ó SE\n",
    "\n",
    "2. ‚úÖ **Correct Interpretation** ‚≠ê‚≠ê:\n",
    "   - ‚úì \"95% of such intervals will capture the true parameter\"\n",
    "   - ‚úó \"There's 95% probability Œº is in this interval\"\n",
    "   - The parameter is **fixed**, the interval is **random**\n",
    "\n",
    "3. ‚úÖ **CI for Mean**:\n",
    "   - œÉ known: xÃÑ ¬± z* √ó (œÉ/‚àön)\n",
    "   - œÉ unknown: xÃÑ ¬± t* √ó (s/‚àön) ‚≠ê (use this!)\n",
    "\n",
    "4. ‚úÖ **CI for Proportion**:\n",
    "   - pÃÇ ¬± z* √ó ‚àö[pÃÇ(1-pÃÇ)/n]\n",
    "   - Requires npÃÇ ‚â• 10 and n(1-pÃÇ) ‚â• 10\n",
    "\n",
    "5. ‚úÖ **Factors Affecting Width**:\n",
    "   - **Sample size** (n): Larger ‚Üí narrower (controllable!)\n",
    "   - **Confidence level**: Higher ‚Üí wider (trade-off)\n",
    "   - **Variability** (œÉ): Higher ‚Üí wider (not controllable)\n",
    "\n",
    "6. ‚úÖ **ML Application** ‚≠ê‚≠ê‚≠ê:\n",
    "   - **Always report model performance with CIs**\n",
    "   - Quantifies uncertainty in performance estimates\n",
    "   - Helps compare models properly\n",
    "   - Bootstrap CI works for any metric\n",
    "\n",
    "### Critical Formulas:\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{CI for mean (œÉ unknown)} = \\bar{x} \\pm t^*_{df} \\times \\frac{s}{\\sqrt{n}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{Width} \\propto \\frac{1}{\\sqrt{n}} \\text{ (to halve width, need 4√ó sample size)}}\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps üöÄ\n",
    "\n",
    "**Coming Up Next: Bootstrap Methods** ‚≠ê‚≠ê\n",
    "\n",
    "We've learned classical confidence intervals (based on formulas and distributional assumptions).\n",
    "\n",
    "But what if:\n",
    "- You want CI for a complex statistic (median, correlation, percentile)?\n",
    "- Distributional assumptions don't hold?\n",
    "- You want a modern, flexible approach?\n",
    "\n",
    "**Answer: Bootstrap!**\n",
    "\n",
    "In the next notebook, we'll learn:\n",
    "- **Bootstrap resampling**: Computer-intensive inference\n",
    "- **Bootstrap CIs**: Works for ANY statistic!\n",
    "- **Connection to ML**: Bootstrap aggregating (bagging) ‚Üí Random Forests ‚≠ê‚≠ê\n",
    "\n",
    "**This is where statistical inference meets modern ML!**\n",
    "\n",
    "See you in **`05_bootstrap_methods.ipynb`**!\n",
    "\n",
    "---\n",
    "\n",
    "**Excellent work! You now know how to quantify uncertainty properly!** üìä‚ú®üåæ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
